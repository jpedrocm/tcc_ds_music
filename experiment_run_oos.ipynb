{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c23fa671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "54e6a756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GB\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.ensemble import IsolationForest as IF\n",
    "from sklearn.dummy import DummyClassifier as DC\n",
    "from sklearn.base import ClassifierMixin, BaseEstimator\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1bf3451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b6bc00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81653e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4fc67dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a667d9",
   "metadata": {},
   "source": [
    "# Experiments for OoS datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9fe587a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_dev_set = pd.read_csv(\"data/dataset/oos_dev_set.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a43b47c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_test_set = pd.read_csv(\"data/dataset/oos_test_set.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eebefa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"explicit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "401e77d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lyrics', 'artist', 'song', 'album_name', 'popularity', 'danceability',\n",
       "       'energy', 'key', 'mode', 'valence', 'tempo', 'duration_ms',\n",
       "       'acousticness', 'liveness', 'loudness', 'speechiness', 'time_signature',\n",
       "       'explicit', 'nb_genres', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oos_dev_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eda74beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_cols = ['popularity', 'danceability','energy', 'key', 'mode', 'valence', 'tempo', 'duration_ms',\n",
    "'acousticness', 'liveness', 'loudness', 'speechiness', 'time_signature', 'nb_genres', 'year']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1532e8",
   "metadata": {},
   "source": [
    "# Custom Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "639ade88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolation Forest binary classifier\n",
    "class IsolationForestClassifier(ClassifierMixin, BaseEstimator):\n",
    "    \n",
    "    def __init__(self, **params):\n",
    "        self.estimator = IF(**params)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        \n",
    "        self.estimator.fit(X)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \n",
    "        preds = self.estimator.predict(X)\n",
    "\n",
    "        # Transform the outputs of IsolationForest scikit-learn class\n",
    "        return np.array(list(map(lambda p: 0 if p==1 else 1, preds)))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.transform(X)\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return self.estimator.get_params()\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        self.estimator.set_params(**parameters)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e977ec1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary binary classifier\n",
    "class DictionaryClassifier(ClassifierMixin, BaseEstimator):\n",
    "    \n",
    "    def __init__(self, random_state=None):\n",
    "        self.random_state=random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "                        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \n",
    "        # Sums transformed input values and assings to true if it's bigger than 0\n",
    "        # To work as a dictionary, one needs to use this class after transforming\n",
    "        # textual attributes to binary vectors containing only dictionary terms\n",
    "        # In this work, this was done using the tfidfvectorizer\n",
    "        preds = [int(x.sum() > 0) for x in X]\n",
    "\n",
    "        return np.array(preds)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0ab6edc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_NB = 5 # number of folds during k-fold cross-validation\n",
    "COMBINATION_NB = 100 # number of k-fold cross-validation runs to find best hyperparams\n",
    "METRICS = [\"f1\", \"recall\", \"f1_macro\", \"recall_macro\"] # metrics to collect during cross validation\n",
    "FOCUS_METRIC = \"f1\" # focus metric to decide best model for each algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "52df5c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLF_SEED = 42 # seed number to pass to each classifier object\n",
    "CV_SEED = 30 # seed number to pass to each cross-validation object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52acf52",
   "metadata": {},
   "source": [
    "# Metadata Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1029c172",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_dev_metadata = oos_dev_set[metadata_cols]\n",
    "oos_dev_target = oos_dev_set[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ddb540f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifiers and tunable hyperparams and values\n",
    "clfs = {\n",
    "    \"DUMMY\": {\n",
    "        'model': DC,\n",
    "        'params': {\n",
    "            'clf__strategy': ['most_frequent', 'uniform', 'stratified']\n",
    "        }\n",
    "    },\n",
    "    \"GB\": {\n",
    "        'model': GB,\n",
    "        'params': {\n",
    "            'scaler__unit_variance': [True, False],\n",
    "            'clf__loss': ['deviance', 'exponential'],\n",
    "            'clf__n_estimators': range(25, 201, 25),\n",
    "            'clf__learning_rate': np.geomspace(0.01, 0.2, 10),\n",
    "            'clf__max_depth': [3, 4, 5],\n",
    "            'clf__max_features': ['sqrt', 'log2', None],\n",
    "            'clf__min_impurity_decrease': [0.00, 0.03, 0.06, 0.09, 0.12]\n",
    "        }\n",
    "    },\n",
    "    \"RF\": {\n",
    "        'model': RF,\n",
    "        'params': {\n",
    "            'scaler__unit_variance': [True, False],\n",
    "            'clf__criterion': ['gini', 'entropy'],\n",
    "            'clf__n_estimators': range(25, 201, 25),\n",
    "            'clf__max_depth': range(3, 9, 1),\n",
    "            'clf__max_features': ['sqrt', 'log2', None],\n",
    "            'clf__min_impurity_decrease': [0.00, 0.03, 0.06, 0.09, 0.12],\n",
    "            'clf__class_weight': ['balanced', 'balanced_subsample', None]\n",
    "        }\n",
    "    },\n",
    "    \"IF\":{\n",
    "        'model': IsolationForestClassifier,\n",
    "        'params': {\n",
    "            'scaler__unit_variance': [True, False],\n",
    "            'clf__n_estimators': range(25, 201, 25),\n",
    "            'clf__bootstrap': [True, False],\n",
    "            'clf__contamination': ['auto', *list(np.geomspace(0.01, 0.15, 10))]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bb958762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DUMMY\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "------------------------\n",
      "GB\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpedrocm/miniconda3/envs/tcc/lib/python3.8/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 3 is smaller than n_iter=100. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "RF\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "------------------------\n",
      "IF\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "rcvs = {}\n",
    "\n",
    "for key in clfs.keys():\n",
    "    print(key)\n",
    "        \n",
    "    chosen_clf = clfs[key]['model']\n",
    "    possible_params = clfs[key]['params']\n",
    "    \n",
    "    pipe_model = Pipeline(steps=[(\"scaler\", RobustScaler()),\n",
    "                                (\"clf\", chosen_clf(random_state=CLF_SEED))]\n",
    "                )\n",
    "        \n",
    "    rcv = RandomizedSearchCV(pipe_model, possible_params,\n",
    "                           scoring=METRICS,\n",
    "                           refit=FOCUS_METRIC,\n",
    "                           n_iter=COMBINATION_NB, cv=CV_NB, n_jobs=-1,\n",
    "                           return_train_score=True,\n",
    "                           verbose=1, random_state=CV_SEED)\n",
    "\n",
    "    X = oos_dev_metadata.values\n",
    "    y = oos_dev_target.values\n",
    "    \n",
    "    rcv.fit(X=X, y=y)\n",
    "    \n",
    "    rcvs[key] = rcv\n",
    "    \n",
    "    print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "69ceeaa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 10.17it/s]\n"
     ]
    }
   ],
   "source": [
    "oos_test_metadata = oos_test_set[metadata_cols]\n",
    "oos_test_target = oos_test_set[target]\n",
    "\n",
    "oos_metadata_metrics = pd.DataFrame(columns=[\"train_f1\", \"train_recall\", \"train_f1_macro\", \"train_recall_macro\",\n",
    "                                             \"test_f1\", \"test_recall\", \"test_f1_macro\", \"test_recall_macro\",\n",
    "                                             \"best_cv_score\", \"refit_time\", \"best_params\"])\n",
    "\n",
    "for key, best_rcv in tqdm(rcvs.items()):\n",
    "    \n",
    "    y_dev_pred = best_rcv.predict(X=oos_dev_metadata.values)\n",
    "    train_f1_bin = f1_score(oos_dev_target.values, y_dev_pred)\n",
    "    train_recall_bin = recall_score(oos_dev_target.values, y_dev_pred)\n",
    "    train_f1_macro = f1_score(oos_dev_target.values, y_dev_pred, average='macro')\n",
    "    train_recall_macro = recall_score(oos_dev_target.values, y_dev_pred, average='macro')\n",
    "\n",
    "    y_test_pred = best_rcv.predict(X=oos_test_metadata.values)\n",
    "    test_f1_bin = f1_score(oos_test_target.values, y_test_pred)\n",
    "    test_recall_bin = recall_score(oos_test_target.values, y_test_pred)\n",
    "    test_f1_macro = f1_score(oos_test_target.values, y_test_pred, average='macro')\n",
    "    test_recall_macro = recall_score(oos_test_target.values, y_test_pred, average='macro')\n",
    "    \n",
    "    oos_metadata_metrics.loc[key] = [train_f1_bin, train_recall_bin, train_f1_macro, train_recall_macro,\n",
    "                                     test_f1_bin, test_recall_bin, test_f1_macro, test_recall_macro,\n",
    "                                     best_rcv.best_score_, best_rcv.refit_time_, str(best_rcv.best_params_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a6c890c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1_macro</th>\n",
       "      <th>train_recall_macro</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>best_cv_score</th>\n",
       "      <th>refit_time</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DUMMY</th>\n",
       "      <td>0.045812</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.352738</td>\n",
       "      <td>0.467436</td>\n",
       "      <td>0.075567</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.355196</td>\n",
       "      <td>0.487705</td>\n",
       "      <td>0.057924</td>\n",
       "      <td>0.005316</td>\n",
       "      <td>{'clf__strategy': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.354037</td>\n",
       "      <td>0.738322</td>\n",
       "      <td>0.675603</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.600862</td>\n",
       "      <td>0.565176</td>\n",
       "      <td>0.133524</td>\n",
       "      <td>0.232417</td>\n",
       "      <td>{'scaler__unit_variance': False, 'clf__n_estim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.438881</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>0.702035</td>\n",
       "      <td>0.930084</td>\n",
       "      <td>0.338710</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.637273</td>\n",
       "      <td>0.795604</td>\n",
       "      <td>0.293175</td>\n",
       "      <td>0.670009</td>\n",
       "      <td>{'scaler__unit_variance': True, 'clf__n_estima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IF</th>\n",
       "      <td>0.100678</td>\n",
       "      <td>0.322981</td>\n",
       "      <td>0.506481</td>\n",
       "      <td>0.588937</td>\n",
       "      <td>0.152542</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.537330</td>\n",
       "      <td>0.591133</td>\n",
       "      <td>0.091054</td>\n",
       "      <td>0.391407</td>\n",
       "      <td>{'scaler__unit_variance': True, 'clf__n_estima...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_f1  train_recall  train_f1_macro  train_recall_macro   test_f1  \\\n",
       "DUMMY  0.045812      0.434783        0.352738            0.467436  0.075567   \n",
       "GB     0.487179      0.354037        0.738322            0.675603  0.222222   \n",
       "RF     0.438881      0.925466        0.702035            0.930084  0.338710   \n",
       "IF     0.100678      0.322981        0.506481            0.588937  0.152542   \n",
       "\n",
       "       test_recall  test_f1_macro  test_recall_macro  best_cv_score  \\\n",
       "DUMMY     0.500000       0.355196           0.487705       0.057924   \n",
       "GB        0.133333       0.600862           0.565176       0.133524   \n",
       "RF        0.700000       0.637273           0.795604       0.293175   \n",
       "IF        0.300000       0.537330           0.591133       0.091054   \n",
       "\n",
       "       refit_time                                        best_params  \n",
       "DUMMY    0.005316                       {'clf__strategy': 'uniform'}  \n",
       "GB       0.232417  {'scaler__unit_variance': False, 'clf__n_estim...  \n",
       "RF       0.670009  {'scaler__unit_variance': True, 'clf__n_estima...  \n",
       "IF       0.391407  {'scaler__unit_variance': True, 'clf__n_estima...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oos_metadata_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ff6a602d",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_metadata_metrics.to_csv('results/oos_metadata_metrics.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a922663",
   "metadata": {},
   "source": [
    "# Lyrics Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c11d75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "68f86de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.Defaults.stop_words |= {'pra', 'pro'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8dc58230",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_stopwords = set()\n",
    "\n",
    "for word in nlp.Defaults.stop_words:\n",
    "    changed_word = word.strip().lower()\n",
    "    pt_stopwords.add(changed_word)\n",
    "\n",
    "    decoded_word = unicodedata.normalize('NFKD', changed_word)\n",
    "    decoded_word = decoded_word.encode('ascii', 'ignore')\n",
    "    decoded_word = decoded_word.decode(\"utf-8\")\n",
    "    \n",
    "    pt_stopwords.add(decoded_word)\n",
    "    \n",
    "pt_stopwords = list(pt_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "44119fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/palavroes.txt', 'r') as f:\n",
    "    offensive_content = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8644c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "offensive_words = {}\n",
    "extra_words = set()\n",
    "\n",
    "for i, word in enumerate(offensive_content):\n",
    "    changed_word = word.strip().lower()\n",
    "    offensive_words[changed_word] = i\n",
    "\n",
    "    decoded_word = unicodedata.normalize('NFKD', changed_word)\n",
    "    decoded_word = decoded_word.encode('ascii', 'ignore')\n",
    "    decoded_word = decoded_word.decode(\"utf-8\")\n",
    "\n",
    "    if changed_word != decoded_word:\n",
    "        extra_words.add(decoded_word)\n",
    "    \n",
    "for i, extra_word in enumerate(extra_words, len(offensive_words)):\n",
    "    offensive_words[extra_word] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "67dfbcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_dev_lyrics = oos_dev_set[['lyrics']]\n",
    "oos_dev_target = oos_dev_set[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b012571f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    \"DUMMY\": {\n",
    "        'model': DC,\n",
    "        'params': {\n",
    "            'clf__strategy': ['most_frequent', 'uniform', 'stratified']\n",
    "        }\n",
    "    },\n",
    "    \"GB\": {\n",
    "        'model': GB,\n",
    "        'params': {\n",
    "            'txt__vectorizer__lowercase': [True],\n",
    "            'txt__vectorizer__strip_accents': ['ascii', None],\n",
    "            'txt__vectorizer__ngram_range': [(1,1), (1,2), (2,2)],\n",
    "            'txt__vectorizer__max_df': np.geomspace(0.8, 1.0, 10),\n",
    "            'txt__vectorizer__min_df': range(1, 5, 1),\n",
    "            'txt__vectorizer__max_features': range(100, 1001, 100),\n",
    "            'txt__vectorizer__binary': [True, False],\n",
    "            'txt__vectorizer__norm': ['l1', 'l2'],\n",
    "            'txt__vectorizer__use_idf': [True, False],\n",
    "            'txt__vectorizer__smooth_idf': [True, False],\n",
    "            'txt__vectorizer__sublinear_tf': [True, False],\n",
    "            'clf__loss': ['deviance', 'exponential'],\n",
    "            'clf__n_estimators': range(25, 201, 25),\n",
    "            'clf__learning_rate': np.geomspace(0.01, 0.2, 10),\n",
    "            'clf__max_depth': [3, 4, 5],\n",
    "            'clf__max_features': ['sqrt', 'log2', None],\n",
    "            'clf__min_impurity_decrease': [0.00, 0.03, 0.06, 0.09, 0.12]\n",
    "        }\n",
    "    },\n",
    "    \"RF\": {\n",
    "        'model': RF,\n",
    "        'params': {\n",
    "            'txt__vectorizer__lowercase': [True],\n",
    "            'txt__vectorizer__strip_accents': ['ascii', None],\n",
    "            'txt__vectorizer__ngram_range': [(1,1), (1,2), (2,2)],\n",
    "            'txt__vectorizer__max_df': np.geomspace(0.8, 1.0, 10),\n",
    "            'txt__vectorizer__min_df': range(1, 5, 1),\n",
    "            'txt__vectorizer__max_features': range(100, 1001, 100),\n",
    "            'txt__vectorizer__binary': [True, False],\n",
    "            'txt__vectorizer__norm': ['l1', 'l2'],\n",
    "            'txt__vectorizer__use_idf': [True, False],\n",
    "            'txt__vectorizer__smooth_idf': [True, False],\n",
    "            'txt__vectorizer__sublinear_tf': [True, False],\n",
    "            'clf__criterion': ['gini', 'entropy'],\n",
    "            'clf__n_estimators': range(25, 201, 25),\n",
    "            'clf__max_depth': range(3, 9, 1),\n",
    "            'clf__max_features': ['sqrt', 'log2', None],\n",
    "            'clf__min_impurity_decrease': [0.00, 0.03, 0.06, 0.09, 0.12],\n",
    "            'clf__class_weight': ['balanced', 'balanced_subsample', None]\n",
    "        }\n",
    "    },\n",
    "    \"IF\":{\n",
    "        'model': IsolationForestClassifier,\n",
    "        'params': {\n",
    "            'txt__vectorizer__lowercase': [True],\n",
    "            'txt__vectorizer__strip_accents': ['ascii', None],\n",
    "            'txt__vectorizer__ngram_range': [(1,1), (1,2), (2,2)],\n",
    "            'txt__vectorizer__max_df': np.geomspace(0.8, 1.0, 10),\n",
    "            'txt__vectorizer__min_df': range(1, 5, 1),\n",
    "            'txt__vectorizer__max_features': range(100, 1001, 100),\n",
    "            'txt__vectorizer__binary': [True, False],\n",
    "            'txt__vectorizer__norm': ['l1', 'l2'],\n",
    "            'txt__vectorizer__use_idf': [True, False],\n",
    "            'txt__vectorizer__smooth_idf': [True, False],\n",
    "            'txt__vectorizer__sublinear_tf': [True, False],\n",
    "            'clf__n_estimators': range(25, 201, 25),\n",
    "            'clf__bootstrap': [True, False],\n",
    "            'clf__contamination': ['auto', *list(np.geomspace(0.01, 0.15, 10))]\n",
    "        }\n",
    "    },\n",
    "    \"DIC\": {\n",
    "        'model': DictionaryClassifier,\n",
    "        'params': {\n",
    "            'txt__vectorizer__lowercase': [True],\n",
    "            'txt__vectorizer__strip_accents': ['ascii'],\n",
    "            'txt__vectorizer__ngram_range': [(1,1)],\n",
    "            'txt__vectorizer__binary': [True],\n",
    "            'txt__vectorizer__use_idf': [False],\n",
    "            'txt__vectorizer__smooth_idf': [False],\n",
    "            'txt__vectorizer__vocabulary': [offensive_words]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6ead887f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DUMMY\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpedrocm/miniconda3/envs/tcc/lib/python3.8/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 3 is smaller than n_iter=100. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "GB\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "------------------------\n",
      "RF\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "------------------------\n",
      "IF\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "------------------------\n",
      "DIC\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpedrocm/miniconda3/envs/tcc/lib/python3.8/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "rcvs = {}\n",
    "\n",
    "for key in list(clfs.keys()):\n",
    "    print(key)\n",
    "\n",
    "    chosen_clf = clfs[key]['model']\n",
    "    possible_params = clfs[key]['params']\n",
    "    \n",
    "    pipe_model = Pipeline(steps=[(\"txt\", ColumnTransformer([(\"vectorizer\", \n",
    "                                                             TfidfVectorizer(stop_words=pt_stopwords), \n",
    "                                                             0)])),\n",
    "                                (\"clf\", chosen_clf(random_state=CLF_SEED))]\n",
    "                )\n",
    "        \n",
    "    rcv = RandomizedSearchCV(pipe_model, possible_params,\n",
    "                           scoring=METRICS,\n",
    "                           refit=FOCUS_METRIC,\n",
    "                           n_iter=COMBINATION_NB, cv=CV_NB, n_jobs=-1,\n",
    "                           return_train_score=True,\n",
    "                           verbose=1, random_state=CV_SEED)\n",
    "\n",
    "    X = oos_dev_lyrics.values\n",
    "    y = oos_dev_target.values\n",
    "    \n",
    "    rcv.fit(X=X, y=y)\n",
    "    \n",
    "    rcvs[key] = rcv\n",
    "    \n",
    "    print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3c7d8773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:04<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "oos_test_lyrics = oos_test_set[['lyrics']]\n",
    "oos_test_target = oos_test_set[target]\n",
    "\n",
    "oos_lyrics_metrics = pd.DataFrame(columns=[\"train_f1\", \"train_recall\", \"train_f1_macro\", \"train_recall_macro\",\n",
    "                                             \"test_f1\", \"test_recall\", \"test_f1_macro\", \"test_recall_macro\",\n",
    "                                             \"best_cv_score\", \"refit_time\", \"best_params\"])\n",
    "\n",
    "for key, best_rcv in tqdm(rcvs.items()):\n",
    "    \n",
    "    y_dev_pred = best_rcv.predict(X=oos_dev_lyrics.values)\n",
    "    train_f1_bin = f1_score(oos_dev_target.values, y_dev_pred)\n",
    "    train_recall_bin = recall_score(oos_dev_target.values, y_dev_pred)\n",
    "    train_f1_macro = f1_score(oos_dev_target.values, y_dev_pred, average='macro')\n",
    "    train_recall_macro = recall_score(oos_dev_target.values, y_dev_pred, average='macro')\n",
    "\n",
    "    y_test_pred = best_rcv.predict(X=oos_test_lyrics.values)\n",
    "    test_f1_bin = f1_score(oos_test_target.values, y_test_pred)\n",
    "    test_recall_bin = recall_score(oos_test_target.values, y_test_pred)\n",
    "    test_f1_macro = f1_score(oos_test_target.values, y_test_pred, average='macro')\n",
    "    test_recall_macro = recall_score(oos_test_target.values, y_test_pred, average='macro')\n",
    "    \n",
    "    oos_lyrics_metrics.loc[key] = [train_f1_bin, train_recall_bin, train_f1_macro, train_recall_macro,\n",
    "                                     test_f1_bin, test_recall_bin, test_f1_macro, test_recall_macro,\n",
    "                                     best_rcv.best_score_, best_rcv.refit_time_, str(best_rcv.best_params_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c004f281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1_macro</th>\n",
       "      <th>train_recall_macro</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>best_cv_score</th>\n",
       "      <th>refit_time</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DUMMY</th>\n",
       "      <td>0.045812</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.352738</td>\n",
       "      <td>0.467436</td>\n",
       "      <td>0.075567</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.355196</td>\n",
       "      <td>0.487705</td>\n",
       "      <td>0.057924</td>\n",
       "      <td>0.639463</td>\n",
       "      <td>{'clf__strategy': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>0.993750</td>\n",
       "      <td>0.987578</td>\n",
       "      <td>0.996787</td>\n",
       "      <td>0.993789</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.643397</td>\n",
       "      <td>0.636587</td>\n",
       "      <td>0.192388</td>\n",
       "      <td>5.824811</td>\n",
       "      <td>{'txt__vectorizer__use_idf': False, 'txt__vect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.497512</td>\n",
       "      <td>0.621118</td>\n",
       "      <td>0.739756</td>\n",
       "      <td>0.798083</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.657603</td>\n",
       "      <td>0.693567</td>\n",
       "      <td>0.373154</td>\n",
       "      <td>1.134479</td>\n",
       "      <td>{'txt__vectorizer__use_idf': True, 'txt__vecto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IF</th>\n",
       "      <td>0.214085</td>\n",
       "      <td>0.236025</td>\n",
       "      <td>0.594663</td>\n",
       "      <td>0.604210</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.586600</td>\n",
       "      <td>0.595057</td>\n",
       "      <td>0.217085</td>\n",
       "      <td>1.470122</td>\n",
       "      <td>{'txt__vectorizer__use_idf': False, 'txt__vect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIC</th>\n",
       "      <td>0.259056</td>\n",
       "      <td>0.732919</td>\n",
       "      <td>0.598024</td>\n",
       "      <td>0.810540</td>\n",
       "      <td>0.290909</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.598163</td>\n",
       "      <td>0.817288</td>\n",
       "      <td>0.270514</td>\n",
       "      <td>0.648424</td>\n",
       "      <td>{'txt__vectorizer__vocabulary': {'anus': 0, '-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_f1  train_recall  train_f1_macro  train_recall_macro   test_f1  \\\n",
       "DUMMY  0.045812      0.434783        0.352738            0.467436  0.075567   \n",
       "GB     0.993750      0.987578        0.996787            0.993789  0.315789   \n",
       "RF     0.497512      0.621118        0.739756            0.798083  0.351351   \n",
       "IF     0.214085      0.236025        0.594663            0.604210  0.212121   \n",
       "DIC    0.259056      0.732919        0.598024            0.810540  0.290909   \n",
       "\n",
       "       test_recall  test_f1_macro  test_recall_macro  best_cv_score  \\\n",
       "DUMMY     0.500000       0.355196           0.487705       0.057924   \n",
       "GB        0.300000       0.643397           0.636587       0.192388   \n",
       "RF        0.433333       0.657603           0.693567       0.373154   \n",
       "IF        0.233333       0.586600           0.595057       0.217085   \n",
       "DIC       0.800000       0.598163           0.817288       0.270514   \n",
       "\n",
       "       refit_time                                        best_params  \n",
       "DUMMY    0.639463                       {'clf__strategy': 'uniform'}  \n",
       "GB       5.824811  {'txt__vectorizer__use_idf': False, 'txt__vect...  \n",
       "RF       1.134479  {'txt__vectorizer__use_idf': True, 'txt__vecto...  \n",
       "IF       1.470122  {'txt__vectorizer__use_idf': False, 'txt__vect...  \n",
       "DIC      0.648424  {'txt__vectorizer__vocabulary': {'anus': 0, '-...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oos_lyrics_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "edddefcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_lyrics_metrics.to_csv('results/oos_lyrics_metrics.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c21b71",
   "metadata": {},
   "source": [
    "# Lyrics and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a272dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_dev_meta_lyrics = oos_dev_set[['lyrics', *metadata_cols]]\n",
    "oos_dev_target = oos_dev_set[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "24796cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    \"DUMMY\": {\n",
    "        'model': DC,\n",
    "        'params': {\n",
    "            'clf__strategy': ['most_frequent', 'uniform', 'stratified']\n",
    "        }\n",
    "    },\n",
    "    \"GB\": {\n",
    "        'model': GB,\n",
    "        'params': {\n",
    "            'col__scaler__unit_variance': [True, False],\n",
    "            'col__vectorizer__lowercase': [True],\n",
    "            'col__vectorizer__strip_accents': ['ascii'],\n",
    "            'col__vectorizer__ngram_range': [(1,1), (1,2), (2,2)],\n",
    "            'col__vectorizer__max_df': np.geomspace(0.8, 1.0, 10),\n",
    "            'col__vectorizer__min_df': range(1, 5, 1),\n",
    "            'col__vectorizer__max_features': range(100, 1001, 100),\n",
    "            'col__vectorizer__binary': [True, False],\n",
    "            'col__vectorizer__norm': ['l1', 'l2'],\n",
    "            'col__vectorizer__use_idf': [True, False],\n",
    "            'col__vectorizer__smooth_idf': [True, False],\n",
    "            'col__vectorizer__sublinear_tf': [True, False],\n",
    "            'clf__loss': ['deviance', 'exponential'],\n",
    "            'clf__n_estimators': range(25, 201, 25),\n",
    "            'clf__learning_rate': np.geomspace(0.01, 0.2, 10),\n",
    "            'clf__max_depth': [3, 4, 5],\n",
    "            'clf__max_features': ['sqrt', 'log2', None],\n",
    "            'clf__min_impurity_decrease': [0.00, 0.03, 0.06, 0.09, 0.12]\n",
    "        }\n",
    "    },\n",
    "    \"RF\": {\n",
    "        'model': RF,\n",
    "        'params': {\n",
    "            'col__scaler__unit_variance': [True, False],\n",
    "            'col__vectorizer__lowercase': [True],\n",
    "            'col__vectorizer__strip_accents': ['ascii'],\n",
    "            'col__vectorizer__ngram_range': [(1,1), (1,2), (2,2)],\n",
    "            'col__vectorizer__max_df': np.geomspace(0.8, 1.0, 10),\n",
    "            'col__vectorizer__min_df': range(1, 5, 1),\n",
    "            'col__vectorizer__max_features': range(100, 1001, 100),\n",
    "            'col__vectorizer__binary': [True, False],\n",
    "            'col__vectorizer__norm': ['l1', 'l2'],\n",
    "            'col__vectorizer__use_idf': [True, False],\n",
    "            'col__vectorizer__smooth_idf': [True, False],\n",
    "            'col__vectorizer__sublinear_tf': [True, False],\n",
    "            'clf__criterion': ['gini', 'entropy'],\n",
    "            'clf__n_estimators': range(25, 201, 25),\n",
    "            'clf__max_depth': range(3, 9, 1),\n",
    "            'clf__max_features': ['sqrt', 'log2', None],\n",
    "            'clf__min_impurity_decrease': [0.00, 0.03, 0.06, 0.09, 0.12],\n",
    "            'clf__class_weight': ['balanced', 'balanced_subsample', None]\n",
    "        }\n",
    "    },\n",
    "    \"IF\":{\n",
    "        'model': IsolationForestClassifier,\n",
    "        'params': {\n",
    "            'col__scaler__unit_variance': [True, False],\n",
    "            'col__vectorizer__lowercase': [True],\n",
    "            'col__vectorizer__strip_accents': ['ascii'],\n",
    "            'col__vectorizer__ngram_range': [(1,1), (1,2), (2,2)],\n",
    "            'col__vectorizer__max_df': np.geomspace(0.8, 1.0, 10),\n",
    "            'col__vectorizer__min_df': range(1, 5, 1),\n",
    "            'col__vectorizer__max_features': range(100, 1001, 100),\n",
    "            'col__vectorizer__binary': [True, False],\n",
    "            'col__vectorizer__norm': ['l1', 'l2'],\n",
    "            'col__vectorizer__use_idf': [True, False],\n",
    "            'col__vectorizer__smooth_idf': [True, False],\n",
    "            'col__vectorizer__sublinear_tf': [True, False],\n",
    "            'clf__n_estimators': range(25, 201, 25),\n",
    "            'clf__bootstrap': [True, False],\n",
    "            'clf__contamination': ['auto', *list(np.geomspace(0.01, 0.15, 10))]\n",
    "        }\n",
    "    },\n",
    "    \"DIC\": {\n",
    "        'model': DictionaryClassifier,\n",
    "        'params': {\n",
    "            'col__vectorizer__lowercase': [True],\n",
    "            'col__vectorizer__strip_accents': ['ascii'],\n",
    "            'col__vectorizer__ngram_range': [(1,1)],\n",
    "            'col__vectorizer__binary': [True],\n",
    "            'col__vectorizer__use_idf': [False],\n",
    "            'col__vectorizer__smooth_idf': [False],\n",
    "            'col__vectorizer__vocabulary': [offensive_words]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "83781a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DUMMY\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpedrocm/miniconda3/envs/tcc/lib/python3.8/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 3 is smaller than n_iter=100. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "GB\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "------------------------\n",
      "RF\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "------------------------\n",
      "IF\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "------------------------\n",
      "DIC\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpedrocm/miniconda3/envs/tcc/lib/python3.8/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "rcvs = {}\n",
    "\n",
    "for key in list(clfs.keys()):\n",
    "    print(key)\n",
    "    \n",
    "    chosen_clf = clfs[key]['model']\n",
    "    possible_params = clfs[key]['params']\n",
    "    \n",
    "    if key != 'DIC':\n",
    "        pipe_model = Pipeline(steps=[(\"col\", ColumnTransformer([(\"scaler\", \n",
    "                                                                 RobustScaler(), \n",
    "                                                                 list(range(1, 16))),\n",
    "\n",
    "                                                                (\"vectorizer\", \n",
    "                                                                 TfidfVectorizer(stop_words=pt_stopwords),\n",
    "                                                                 0)])),\n",
    "                                    (\"clf\", chosen_clf(random_state=CLF_SEED))]\n",
    "                            )\n",
    "        \n",
    "        X = oos_dev_meta_lyrics.values\n",
    "    else:\n",
    "        pipe_model = Pipeline(steps=[(\"col\", ColumnTransformer([(\"vectorizer\", \n",
    "                                                                 TfidfVectorizer(stop_words=pt_stopwords),\n",
    "                                                                 0)])),\n",
    "                                    (\"clf\", chosen_clf())]\n",
    "                            )\n",
    "        X = oos_dev_lyrics.values\n",
    "        \n",
    "        \n",
    "    rcv = RandomizedSearchCV(pipe_model, possible_params,\n",
    "                           scoring=METRICS,\n",
    "                           refit=FOCUS_METRIC,\n",
    "                           n_iter=COMBINATION_NB, cv=CV_NB, n_jobs=-1,\n",
    "                           return_train_score=True,\n",
    "                           verbose=1, random_state=CV_SEED)\n",
    "\n",
    "    y = oos_dev_target.values\n",
    "    \n",
    "    rcv.fit(X=X, y=y)\n",
    "    \n",
    "    rcvs[key] = rcv\n",
    "    \n",
    "    print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ebe80354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:05<00:00,  1.13s/it]\n"
     ]
    }
   ],
   "source": [
    "oos_test_meta_lyrics = oos_test_set[['lyrics', *metadata_cols]]\n",
    "oos_test_target = oos_test_set[target]\n",
    "\n",
    "oos_meta_lyrics_metrics = pd.DataFrame(columns=[\"train_f1\", \"train_recall\", \"train_f1_macro\", \"train_recall_macro\",\n",
    "                                             \"test_f1\", \"test_recall\", \"test_f1_macro\", \"test_recall_macro\",\n",
    "                                             \"best_cv_score\", \"refit_time\", \"best_params\"])\n",
    "\n",
    "for key, best_rcv in tqdm(rcvs.items()):\n",
    "    \n",
    "    if key != 'DIC':\n",
    "        y_dev_pred = best_rcv.predict(X=oos_dev_meta_lyrics.values)\n",
    "        train_f1_bin = f1_score(oos_dev_target.values, y_dev_pred)\n",
    "        train_recall_bin = recall_score(oos_dev_target.values, y_dev_pred)\n",
    "        train_f1_macro = f1_score(oos_dev_target.values, y_dev_pred, average='macro')\n",
    "        train_recall_macro = recall_score(oos_dev_target.values, y_dev_pred, average='macro')\n",
    "\n",
    "        y_test_pred = best_rcv.predict(X=oos_test_meta_lyrics.values)\n",
    "        test_f1_bin = f1_score(oos_test_target.values, y_test_pred)\n",
    "        test_recall_bin = recall_score(oos_test_target.values, y_test_pred)\n",
    "        test_f1_macro = f1_score(oos_test_target.values, y_test_pred, average='macro')\n",
    "        test_recall_macro = recall_score(oos_test_target.values, y_test_pred, average='macro')\n",
    "    else:\n",
    "        y_dev_pred = best_rcv.predict(X=oos_dev_lyrics.values)\n",
    "        train_f1_bin = f1_score(oos_dev_target.values, y_dev_pred)\n",
    "        train_recall_bin = recall_score(oos_dev_target.values, y_dev_pred)\n",
    "        train_f1_macro = f1_score(oos_dev_target.values, y_dev_pred, average='macro')\n",
    "        train_recall_macro = recall_score(oos_dev_target.values, y_dev_pred, average='macro')\n",
    "\n",
    "        y_test_pred = best_rcv.predict(X=oos_test_lyrics.values)\n",
    "        test_f1_bin = f1_score(oos_test_target.values, y_test_pred)\n",
    "        test_recall_bin = recall_score(oos_test_target.values, y_test_pred)\n",
    "        test_f1_macro = f1_score(oos_test_target.values, y_test_pred, average='macro')\n",
    "        test_recall_macro = recall_score(oos_test_target.values, y_test_pred, average='macro')\n",
    "    \n",
    "    oos_meta_lyrics_metrics.loc[key] = [train_f1_bin, train_recall_bin, train_f1_macro, train_recall_macro,\n",
    "                                     test_f1_bin, test_recall_bin, test_f1_macro, test_recall_macro,\n",
    "                                     best_rcv.best_score_, best_rcv.refit_time_, str(best_rcv.best_params_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d3dfc840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1_macro</th>\n",
       "      <th>train_recall_macro</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>best_cv_score</th>\n",
       "      <th>refit_time</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DUMMY</th>\n",
       "      <td>0.045812</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.352738</td>\n",
       "      <td>0.467436</td>\n",
       "      <td>0.075567</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.355196</td>\n",
       "      <td>0.487705</td>\n",
       "      <td>0.057924</td>\n",
       "      <td>0.665721</td>\n",
       "      <td>{'clf__strategy': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.472727</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.725599</td>\n",
       "      <td>0.707725</td>\n",
       "      <td>0.178096</td>\n",
       "      <td>8.862804</td>\n",
       "      <td>{'col__vectorizer__use_idf': False, 'col__vect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.440735</td>\n",
       "      <td>0.819876</td>\n",
       "      <td>0.705175</td>\n",
       "      <td>0.882863</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.626961</td>\n",
       "      <td>0.737134</td>\n",
       "      <td>0.362555</td>\n",
       "      <td>2.622577</td>\n",
       "      <td>{'col__vectorizer__use_idf': True, 'col__vecto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IF</th>\n",
       "      <td>0.197183</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.585946</td>\n",
       "      <td>0.594627</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.582701</td>\n",
       "      <td>0.593567</td>\n",
       "      <td>0.254769</td>\n",
       "      <td>2.307955</td>\n",
       "      <td>{'col__vectorizer__use_idf': False, 'col__vect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIC</th>\n",
       "      <td>0.259056</td>\n",
       "      <td>0.732919</td>\n",
       "      <td>0.598024</td>\n",
       "      <td>0.810540</td>\n",
       "      <td>0.290909</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.598163</td>\n",
       "      <td>0.817288</td>\n",
       "      <td>0.270514</td>\n",
       "      <td>0.702295</td>\n",
       "      <td>{'col__vectorizer__vocabulary': {'anus': 0, '-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_f1  train_recall  train_f1_macro  train_recall_macro   test_f1  \\\n",
       "DUMMY  0.045812      0.434783        0.352738            0.467436  0.075567   \n",
       "GB     1.000000      1.000000        1.000000            1.000000  0.472727   \n",
       "RF     0.440735      0.819876        0.705175            0.882863  0.311927   \n",
       "IF     0.197183      0.217391        0.585946            0.594627  0.205882   \n",
       "DIC    0.259056      0.732919        0.598024            0.810540  0.290909   \n",
       "\n",
       "       test_recall  test_f1_macro  test_recall_macro  best_cv_score  \\\n",
       "DUMMY     0.500000       0.355196           0.487705       0.057924   \n",
       "GB        0.433333       0.725599           0.707725       0.178096   \n",
       "RF        0.566667       0.626961           0.737134       0.362555   \n",
       "IF        0.233333       0.582701           0.593567       0.254769   \n",
       "DIC       0.800000       0.598163           0.817288       0.270514   \n",
       "\n",
       "       refit_time                                        best_params  \n",
       "DUMMY    0.665721                       {'clf__strategy': 'uniform'}  \n",
       "GB       8.862804  {'col__vectorizer__use_idf': False, 'col__vect...  \n",
       "RF       2.622577  {'col__vectorizer__use_idf': True, 'col__vecto...  \n",
       "IF       2.307955  {'col__vectorizer__use_idf': False, 'col__vect...  \n",
       "DIC      0.702295  {'col__vectorizer__vocabulary': {'anus': 0, '-...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oos_meta_lyrics_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "764fd805",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_meta_lyrics_metrics.to_csv('results/oos_meta_lyrics_metrics.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
