{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c23fa671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54e6a756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GB\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.ensemble import IsolationForest as IF\n",
    "from sklearn.dummy import DummyClassifier as DC\n",
    "from sklearn.base import ClassifierMixin, BaseEstimator\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bf3451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b6bc00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81653e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fc67dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fe587a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_dev_set = pd.read_csv(\"data/dataset/oos_dev_set.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a43b47c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_test_set = pd.read_csv(\"data/dataset/oos_test_set.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eebefa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"explicit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "401e77d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lyrics', 'artist', 'song', 'album_name', 'popularity', 'danceability',\n",
       "       'energy', 'key', 'mode', 'valence', 'tempo', 'duration_ms',\n",
       "       'acousticness', 'liveness', 'loudness', 'speechiness', 'time_signature',\n",
       "       'explicit', 'nb_genres', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oos_dev_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eda74beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_cols = ['popularity', 'danceability','energy', 'key', 'mode', 'valence', 'tempo', 'duration_ms',\n",
    "'acousticness', 'liveness', 'loudness', 'speechiness', 'time_signature', 'nb_genres', 'year']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1532e8",
   "metadata": {},
   "source": [
    "# Custom Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "639ade88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IsolationForestClassifier(ClassifierMixin, BaseEstimator):\n",
    "    \n",
    "    def __init__(self, **params):\n",
    "        self.estimator = IF(**params)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        \n",
    "        self.estimator.fit(X)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \n",
    "        preds = self.estimator.predict(X)\n",
    "\n",
    "        return np.array(list(map(lambda p: 0 if p==1 else 1, preds)))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.transform(X)\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return self.estimator.get_params()\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        self.estimator.set_params(**parameters)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e977ec1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DictionaryClassifier(ClassifierMixin, BaseEstimator):\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "                        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \n",
    "        preds = [int(x.sum() > 0) for x in X]\n",
    "\n",
    "        return np.array(preds)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ab6edc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_NB = 5\n",
    "COMBINATION_NB = 100\n",
    "METRICS = [\"f1\", \"recall\", \"f1_macro\", \"recall_macro\"]\n",
    "FOCUS_METRIC = \"f1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52acf52",
   "metadata": {},
   "source": [
    "# Metadata Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1029c172",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_dev_metadata = oos_dev_set[metadata_cols]\n",
    "oos_dev_target = oos_dev_set[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddb540f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    \"DUMMY\": {\n",
    "        'model': DC(),\n",
    "        'params': {\n",
    "            'clf__strategy': ['most_frequent', 'uniform', 'stratified']\n",
    "        }\n",
    "    },\n",
    "    \"GB\": {\n",
    "        'model': GB(),\n",
    "        'params': {\n",
    "            'scaler__unit_variance': [True, False],\n",
    "            'clf__loss': ['deviance', 'exponential'],\n",
    "            'clf__n_estimators': range(25, 201, 25),\n",
    "            'clf__learning_rate': np.geomspace(0.01, 0.2, 10),\n",
    "            'clf__max_depth': [3, 4, 5],\n",
    "            'clf__max_features': ['sqrt', 'log2', None],\n",
    "            'clf__min_impurity_decrease': [0.00, 0.03, 0.06, 0.09, 0.12]\n",
    "        }\n",
    "    },\n",
    "    \"RF\": {\n",
    "        'model': RF(),\n",
    "        'params': {\n",
    "            'scaler__unit_variance': [True, False],\n",
    "            'clf__criterion': ['gini', 'entropy'],\n",
    "            'clf__n_estimators': range(25, 201, 25),\n",
    "            'clf__max_depth': range(3, 9, 1),\n",
    "            'clf__max_features': ['sqrt', 'log2', None],\n",
    "            'clf__min_impurity_decrease': [0.00, 0.03, 0.06, 0.09, 0.12],\n",
    "            'clf__class_weight': ['balanced', 'balanced_subsample', None]\n",
    "        }\n",
    "    },\n",
    "    \"IF\":{\n",
    "        'model': IsolationForestClassifier(),\n",
    "        'params': {\n",
    "            'scaler__unit_variance': [True, False],\n",
    "            'clf__n_estimators': range(25, 201, 25),\n",
    "            'clf__contamination': ['auto', *list(np.geomspace(0.01, 0.15, 10))]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb958762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DUMMY\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpedrocm/miniconda3/envs/tcc/lib/python3.8/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 3 is smaller than n_iter=100. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "GB\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "------------------------\n",
      "RF\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "------------------------\n",
      "IF\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "rcvs = {}\n",
    "\n",
    "for key in clfs.keys():\n",
    "    print(key)\n",
    "    \n",
    "    np.random.seed(32)\n",
    "    random.seed(24)\n",
    "    \n",
    "    chosen_clf = clfs[key]['model']\n",
    "    possible_params = clfs[key]['params']\n",
    "    \n",
    "    pipe_model = Pipeline(steps=[(\"scaler\", RobustScaler()),\n",
    "                                (\"clf\", chosen_clf)]\n",
    "                )\n",
    "        \n",
    "    rcv = RandomizedSearchCV(pipe_model, possible_params,\n",
    "                           scoring=METRICS,\n",
    "                           refit=FOCUS_METRIC,\n",
    "                           n_iter=COMBINATION_NB, cv=CV_NB, n_jobs=-1,\n",
    "                           return_train_score=True,\n",
    "                           verbose=1)\n",
    "\n",
    "    X = oos_dev_metadata.values\n",
    "    y = oos_dev_target.values\n",
    "    \n",
    "    rcv.fit(X=X, y=y)\n",
    "    \n",
    "    rcvs[key] = rcv\n",
    "    \n",
    "    print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69ceeaa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.02it/s]\n"
     ]
    }
   ],
   "source": [
    "oos_test_metadata = oos_test_set[metadata_cols]\n",
    "oos_test_target = oos_test_set[target]\n",
    "\n",
    "oos_metadata_metrics = pd.DataFrame(columns=[\"train_f1\", \"train_recall\", \"train_f1_macro\", \"train_recall_macro\",\n",
    "                                             \"test_f1\", \"test_recall\", \"test_f1_macro\", \"test_recall_macro\",\n",
    "                                             \"best_cv_score\", \"refit_time\", \"best_params\"])\n",
    "\n",
    "for key, best_rcv in tqdm(rcvs.items()):\n",
    "        \n",
    "    np.random.seed(32)\n",
    "    random.seed(24)\n",
    "    \n",
    "    y_dev_pred = best_rcv.predict(X=oos_dev_metadata.values)\n",
    "    train_f1_bin = f1_score(oos_dev_target.values, y_dev_pred)\n",
    "    train_recall_bin = recall_score(oos_dev_target.values, y_dev_pred)\n",
    "    train_f1_macro = f1_score(oos_dev_target.values, y_dev_pred, average='macro')\n",
    "    train_recall_macro = recall_score(oos_dev_target.values, y_dev_pred, average='macro')\n",
    "\n",
    "    y_test_pred = best_rcv.predict(X=oos_test_metadata.values)\n",
    "    test_f1_bin = f1_score(oos_test_target.values, y_test_pred)\n",
    "    test_recall_bin = recall_score(oos_test_target.values, y_test_pred)\n",
    "    test_f1_macro = f1_score(oos_test_target.values, y_test_pred, average='macro')\n",
    "    test_recall_macro = recall_score(oos_test_target.values, y_test_pred, average='macro')\n",
    "    \n",
    "    oos_metadata_metrics.loc[key] = [train_f1_bin, train_recall_bin, train_f1_macro, train_recall_macro,\n",
    "                                     test_f1_bin, test_recall_bin, test_f1_macro, test_recall_macro,\n",
    "                                     best_rcv.best_score_, best_rcv.refit_time_, str(best_rcv.best_params_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6c890c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1_macro</th>\n",
       "      <th>train_recall_macro</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>best_cv_score</th>\n",
       "      <th>refit_time</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DUMMY</th>\n",
       "      <td>0.057629</td>\n",
       "      <td>0.546584</td>\n",
       "      <td>0.360903</td>\n",
       "      <td>0.525106</td>\n",
       "      <td>0.085960</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.391508</td>\n",
       "      <td>0.523472</td>\n",
       "      <td>0.052158</td>\n",
       "      <td>0.006168</td>\n",
       "      <td>{'clf__strategy': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>0.707692</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.850502</td>\n",
       "      <td>0.785095</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.575107</td>\n",
       "      <td>0.548510</td>\n",
       "      <td>0.120659</td>\n",
       "      <td>0.237554</td>\n",
       "      <td>{'scaler__unit_variance': False, 'clf__n_estim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.503289</td>\n",
       "      <td>0.950311</td>\n",
       "      <td>0.737937</td>\n",
       "      <td>0.949142</td>\n",
       "      <td>0.330275</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.636909</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.268791</td>\n",
       "      <td>1.136282</td>\n",
       "      <td>{'scaler__unit_variance': False, 'clf__n_estim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IF</th>\n",
       "      <td>0.106643</td>\n",
       "      <td>0.378882</td>\n",
       "      <td>0.504562</td>\n",
       "      <td>0.607863</td>\n",
       "      <td>0.170213</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.538715</td>\n",
       "      <td>0.626230</td>\n",
       "      <td>0.103646</td>\n",
       "      <td>0.183662</td>\n",
       "      <td>{'scaler__unit_variance': True, 'clf__n_estima...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_f1  train_recall  train_f1_macro  train_recall_macro   test_f1  \\\n",
       "DUMMY  0.057629      0.546584        0.360903            0.525106  0.085960   \n",
       "GB     0.707692      0.571429        0.850502            0.785095  0.171429   \n",
       "RF     0.503289      0.950311        0.737937            0.949142  0.330275   \n",
       "IF     0.106643      0.378882        0.504562            0.607863  0.170213   \n",
       "\n",
       "       test_recall  test_f1_macro  test_recall_macro  best_cv_score  \\\n",
       "DUMMY          0.5       0.391508           0.523472       0.052158   \n",
       "GB             0.1       0.575107           0.548510       0.120659   \n",
       "RF             0.6       0.636909           0.754545       0.268791   \n",
       "IF             0.4       0.538715           0.626230       0.103646   \n",
       "\n",
       "       refit_time                                        best_params  \n",
       "DUMMY    0.006168                       {'clf__strategy': 'uniform'}  \n",
       "GB       0.237554  {'scaler__unit_variance': False, 'clf__n_estim...  \n",
       "RF       1.136282  {'scaler__unit_variance': False, 'clf__n_estim...  \n",
       "IF       0.183662  {'scaler__unit_variance': True, 'clf__n_estima...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oos_metadata_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff6a602d",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_metadata_metrics.to_csv('results/oos_metadata_metrics.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a922663",
   "metadata": {},
   "source": [
    "# Lyrics Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c11d75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68f86de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.Defaults.stop_words |= {'pra', 'pro'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8dc58230",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_stopwords = set()\n",
    "\n",
    "for word in nlp.Defaults.stop_words:\n",
    "    changed_word = word.strip().lower()\n",
    "    pt_stopwords.add(changed_word)\n",
    "\n",
    "    decoded_word = unicodedata.normalize('NFKD', changed_word)\n",
    "    decoded_word = decoded_word.encode('ascii', 'ignore')\n",
    "    decoded_word = decoded_word.decode(\"utf-8\")\n",
    "    \n",
    "    pt_stopwords.add(decoded_word)\n",
    "    \n",
    "pt_stopwords = list(pt_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44119fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/palavroes.txt', 'r') as f:\n",
    "    offensive_content = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8644c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "offensive_words = {}\n",
    "extra_words = set()\n",
    "\n",
    "for i, word in enumerate(offensive_content):\n",
    "    changed_word = word.strip().lower()\n",
    "    offensive_words[changed_word] = i\n",
    "\n",
    "    decoded_word = unicodedata.normalize('NFKD', changed_word)\n",
    "    decoded_word = decoded_word.encode('ascii', 'ignore')\n",
    "    decoded_word = decoded_word.decode(\"utf-8\")\n",
    "\n",
    "    if changed_word != decoded_word:\n",
    "        extra_words.add(decoded_word)\n",
    "    \n",
    "for i, extra_word in enumerate(extra_words, len(offensive_words)):\n",
    "    offensive_words[extra_word] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67dfbcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_dev_lyrics = oos_dev_set[['lyrics']]\n",
    "oos_dev_target = oos_dev_set[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b012571f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    \"DUMMY\": {\n",
    "        'model': DC(),\n",
    "        'params': {\n",
    "            'clf__strategy': ['most_frequent', 'uniform', 'stratified']\n",
    "        }\n",
    "    },\n",
    "    \"GB\": {\n",
    "        'model': GB(),\n",
    "        'params': {\n",
    "            'txt__vectorizer__lowercase': [True],\n",
    "            'txt__vectorizer__strip_accents': ['ascii', None],\n",
    "            'txt__vectorizer__ngram_range': [(1,1), (1,2), (2,2)],\n",
    "            'txt__vectorizer__max_df': np.geomspace(0.8, 1.0, 10),\n",
    "            'txt__vectorizer__min_df': range(1, 5, 1),\n",
    "            'txt__vectorizer__max_features': range(100, 1001, 100),\n",
    "            'txt__vectorizer__binary': [True, False],\n",
    "            'txt__vectorizer__norm': ['l1', 'l2'],\n",
    "            'txt__vectorizer__use_idf': [True, False],\n",
    "            'txt__vectorizer__smooth_idf': [True, False],\n",
    "            'txt__vectorizer__sublinear_tf': [True, False],\n",
    "            'clf__loss': ['deviance', 'exponential'],\n",
    "            'clf__n_estimators': range(25, 201, 25),\n",
    "            'clf__learning_rate': np.geomspace(0.01, 0.2, 10),\n",
    "            'clf__max_depth': [3, 4, 5],\n",
    "            'clf__max_features': ['sqrt', 'log2', None],\n",
    "            'clf__min_impurity_decrease': [0.00, 0.03, 0.06, 0.09, 0.12]\n",
    "        }\n",
    "    },\n",
    "    \"RF\": {\n",
    "        'model': RF(),\n",
    "        'params': {\n",
    "            'txt__vectorizer__lowercase': [True],\n",
    "            'txt__vectorizer__strip_accents': ['ascii', None],\n",
    "            'txt__vectorizer__ngram_range': [(1,1), (1,2), (2,2)],\n",
    "            'txt__vectorizer__max_df': np.geomspace(0.8, 1.0, 10),\n",
    "            'txt__vectorizer__min_df': range(1, 5, 1),\n",
    "            'txt__vectorizer__max_features': range(100, 1001, 100),\n",
    "            'txt__vectorizer__binary': [True, False],\n",
    "            'txt__vectorizer__norm': ['l1', 'l2'],\n",
    "            'txt__vectorizer__use_idf': [True, False],\n",
    "            'txt__vectorizer__smooth_idf': [True, False],\n",
    "            'txt__vectorizer__sublinear_tf': [True, False],\n",
    "            'clf__criterion': ['gini', 'entropy'],\n",
    "            'clf__n_estimators': range(25, 201, 25),\n",
    "            'clf__max_depth': range(3, 9, 1),\n",
    "            'clf__max_features': ['sqrt', 'log2', None],\n",
    "            'clf__min_impurity_decrease': [0.00, 0.03, 0.06, 0.09, 0.12],\n",
    "            'clf__class_weight': ['balanced', 'balanced_subsample', None]\n",
    "        }\n",
    "    },\n",
    "    \"IF\":{\n",
    "        'model': IsolationForestClassifier(),\n",
    "        'params': {\n",
    "            'txt__vectorizer__lowercase': [True],\n",
    "            'txt__vectorizer__strip_accents': ['ascii', None],\n",
    "            'txt__vectorizer__ngram_range': [(1,1), (1,2), (2,2)],\n",
    "            'txt__vectorizer__max_df': np.geomspace(0.8, 1.0, 10),\n",
    "            'txt__vectorizer__min_df': range(1, 5, 1),\n",
    "            'txt__vectorizer__max_features': range(100, 1001, 100),\n",
    "            'txt__vectorizer__binary': [True, False],\n",
    "            'txt__vectorizer__norm': ['l1', 'l2'],\n",
    "            'txt__vectorizer__use_idf': [True, False],\n",
    "            'txt__vectorizer__smooth_idf': [True, False],\n",
    "            'txt__vectorizer__sublinear_tf': [True, False],\n",
    "            'clf__n_estimators': range(25, 201, 25),\n",
    "            'clf__contamination': ['auto', *list(np.geomspace(0.01, 0.15, 10))]\n",
    "        }\n",
    "    },\n",
    "    \"DIC\": {\n",
    "        'model': DictionaryClassifier(),\n",
    "        'params': {\n",
    "            'txt__vectorizer__lowercase': [True],\n",
    "            'txt__vectorizer__strip_accents': ['ascii'],\n",
    "            'txt__vectorizer__ngram_range': [(1,1)],\n",
    "            'txt__vectorizer__binary': [True],\n",
    "            'txt__vectorizer__use_idf': [False],\n",
    "            'txt__vectorizer__smooth_idf': [False],\n",
    "            'txt__vectorizer__vocabulary': [offensive_words]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ead887f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DUMMY\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpedrocm/miniconda3/envs/tcc/lib/python3.8/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 3 is smaller than n_iter=100. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "GB\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "------------------------\n",
      "RF\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "------------------------\n",
      "IF\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "------------------------\n",
      "DIC\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpedrocm/miniconda3/envs/tcc/lib/python3.8/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "rcvs = {}\n",
    "\n",
    "for key in list(clfs.keys()):\n",
    "    print(key)\n",
    "    \n",
    "    np.random.seed(32)\n",
    "    random.seed(24)\n",
    "    \n",
    "    chosen_clf = clfs[key]['model']\n",
    "    possible_params = clfs[key]['params']\n",
    "    \n",
    "    pipe_model = Pipeline(steps=[(\"txt\", ColumnTransformer([(\"vectorizer\", \n",
    "                                                             TfidfVectorizer(stop_words=pt_stopwords), \n",
    "                                                             0)])),\n",
    "                                (\"clf\", chosen_clf)]\n",
    "                )\n",
    "        \n",
    "    rcv = RandomizedSearchCV(pipe_model, possible_params,\n",
    "                           scoring=METRICS,\n",
    "                           refit=FOCUS_METRIC,\n",
    "                           n_iter=COMBINATION_NB, cv=CV_NB, n_jobs=-1,\n",
    "                           return_train_score=True,\n",
    "                           verbose=1)\n",
    "\n",
    "    X = oos_dev_lyrics.values\n",
    "    y = oos_dev_target.values\n",
    "    \n",
    "    rcv.fit(X=X, y=y)\n",
    "    \n",
    "    rcvs[key] = rcv\n",
    "    \n",
    "    print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c7d8773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:05<00:00,  1.11s/it]\n"
     ]
    }
   ],
   "source": [
    "oos_test_lyrics = oos_test_set[['lyrics']]\n",
    "oos_test_target = oos_test_set[target]\n",
    "\n",
    "oos_lyrics_metrics = pd.DataFrame(columns=[\"train_f1\", \"train_recall\", \"train_f1_macro\", \"train_recall_macro\",\n",
    "                                             \"test_f1\", \"test_recall\", \"test_f1_macro\", \"test_recall_macro\",\n",
    "                                             \"best_cv_score\", \"refit_time\", \"best_params\"])\n",
    "\n",
    "for key, best_rcv in tqdm(rcvs.items()):\n",
    "        \n",
    "    np.random.seed(32)\n",
    "    random.seed(24)\n",
    "    \n",
    "    y_dev_pred = best_rcv.predict(X=oos_dev_lyrics.values)\n",
    "    train_f1_bin = f1_score(oos_dev_target.values, y_dev_pred)\n",
    "    train_recall_bin = recall_score(oos_dev_target.values, y_dev_pred)\n",
    "    train_f1_macro = f1_score(oos_dev_target.values, y_dev_pred, average='macro')\n",
    "    train_recall_macro = recall_score(oos_dev_target.values, y_dev_pred, average='macro')\n",
    "\n",
    "    y_test_pred = best_rcv.predict(X=oos_test_lyrics.values)\n",
    "    test_f1_bin = f1_score(oos_test_target.values, y_test_pred)\n",
    "    test_recall_bin = recall_score(oos_test_target.values, y_test_pred)\n",
    "    test_f1_macro = f1_score(oos_test_target.values, y_test_pred, average='macro')\n",
    "    test_recall_macro = recall_score(oos_test_target.values, y_test_pred, average='macro')\n",
    "    \n",
    "    oos_lyrics_metrics.loc[key] = [train_f1_bin, train_recall_bin, train_f1_macro, train_recall_macro,\n",
    "                                     test_f1_bin, test_recall_bin, test_f1_macro, test_recall_macro,\n",
    "                                     best_rcv.best_score_, best_rcv.refit_time_, str(best_rcv.best_params_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c004f281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1_macro</th>\n",
       "      <th>train_recall_macro</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>best_cv_score</th>\n",
       "      <th>refit_time</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DUMMY</th>\n",
       "      <td>0.055728</td>\n",
       "      <td>0.055901</td>\n",
       "      <td>0.514369</td>\n",
       "      <td>0.514413</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.484938</td>\n",
       "      <td>0.491803</td>\n",
       "      <td>0.056304</td>\n",
       "      <td>0.619733</td>\n",
       "      <td>{'clf__strategy': 'stratified'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.621118</td>\n",
       "      <td>0.874497</td>\n",
       "      <td>0.810205</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.624582</td>\n",
       "      <td>0.594039</td>\n",
       "      <td>0.182910</td>\n",
       "      <td>1.822797</td>\n",
       "      <td>{'txt__vectorizer__use_idf': False, 'txt__vect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.473573</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.725622</td>\n",
       "      <td>0.830130</td>\n",
       "      <td>0.263736</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.606315</td>\n",
       "      <td>0.663487</td>\n",
       "      <td>0.349886</td>\n",
       "      <td>2.619981</td>\n",
       "      <td>{'txt__vectorizer__use_idf': True, 'txt__vecto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IF</th>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.124224</td>\n",
       "      <td>0.553868</td>\n",
       "      <td>0.551140</td>\n",
       "      <td>0.237288</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.601891</td>\n",
       "      <td>0.600273</td>\n",
       "      <td>0.189856</td>\n",
       "      <td>1.351412</td>\n",
       "      <td>{'txt__vectorizer__use_idf': False, 'txt__vect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIC</th>\n",
       "      <td>0.259056</td>\n",
       "      <td>0.732919</td>\n",
       "      <td>0.598024</td>\n",
       "      <td>0.810540</td>\n",
       "      <td>0.290909</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.598163</td>\n",
       "      <td>0.817288</td>\n",
       "      <td>0.270514</td>\n",
       "      <td>0.655242</td>\n",
       "      <td>{'txt__vectorizer__vocabulary': {'anus': 0, '-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_f1  train_recall  train_f1_macro  train_recall_macro   test_f1  \\\n",
       "DUMMY  0.055728      0.055901        0.514369            0.514413  0.000000   \n",
       "GB     0.754717      0.621118        0.874497            0.810205  0.272727   \n",
       "RF     0.473573      0.695652        0.725622            0.830130  0.263736   \n",
       "IF     0.131148      0.124224        0.553868            0.551140  0.237288   \n",
       "DIC    0.259056      0.732919        0.598024            0.810540  0.290909   \n",
       "\n",
       "       test_recall  test_f1_macro  test_recall_macro  best_cv_score  \\\n",
       "DUMMY     0.000000       0.484938           0.491803       0.056304   \n",
       "GB        0.200000       0.624582           0.594039       0.182910   \n",
       "RF        0.400000       0.606315           0.663487       0.349886   \n",
       "IF        0.233333       0.601891           0.600273       0.189856   \n",
       "DIC       0.800000       0.598163           0.817288       0.270514   \n",
       "\n",
       "       refit_time                                        best_params  \n",
       "DUMMY    0.619733                    {'clf__strategy': 'stratified'}  \n",
       "GB       1.822797  {'txt__vectorizer__use_idf': False, 'txt__vect...  \n",
       "RF       2.619981  {'txt__vectorizer__use_idf': True, 'txt__vecto...  \n",
       "IF       1.351412  {'txt__vectorizer__use_idf': False, 'txt__vect...  \n",
       "DIC      0.655242  {'txt__vectorizer__vocabulary': {'anus': 0, '-...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oos_lyrics_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "edddefcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_lyrics_metrics.to_csv('results/oos_lyrics_metrics.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c21b71",
   "metadata": {},
   "source": [
    "# Lyrics and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a272dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_dev_meta_lyrics = oos_dev_set[['lyrics', *metadata_cols]]\n",
    "oos_dev_target = oos_dev_set[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24796cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    \"DUMMY\": {\n",
    "        'model': DC(),\n",
    "        'params': {\n",
    "            'clf__strategy': ['most_frequent', 'uniform', 'stratified']\n",
    "        }\n",
    "    },\n",
    "    \"GB\": {\n",
    "        'model': GB(),\n",
    "        'params': {\n",
    "            'col__scaler__unit_variance': [True, False],\n",
    "            'col__vectorizer__lowercase': [True],\n",
    "            'col__vectorizer__strip_accents': ['ascii'],\n",
    "            'col__vectorizer__ngram_range': [(1,1), (1,2), (2,2)],\n",
    "            'col__vectorizer__max_df': np.geomspace(0.8, 1.0, 10),\n",
    "            'col__vectorizer__min_df': range(1, 5, 1),\n",
    "            'col__vectorizer__max_features': range(100, 1001, 100),\n",
    "            'col__vectorizer__binary': [True, False],\n",
    "            'col__vectorizer__norm': ['l1', 'l2'],\n",
    "            'col__vectorizer__use_idf': [True, False],\n",
    "            'col__vectorizer__smooth_idf': [True, False],\n",
    "            'col__vectorizer__sublinear_tf': [True, False],\n",
    "            'clf__loss': ['deviance', 'exponential'],\n",
    "            'clf__n_estimators': range(25, 201, 25),\n",
    "            'clf__learning_rate': np.geomspace(0.01, 0.2, 10),\n",
    "            'clf__max_depth': [3, 4, 5],\n",
    "            'clf__max_features': ['sqrt', 'log2', None],\n",
    "            'clf__min_impurity_decrease': [0.00, 0.03, 0.06, 0.09, 0.12]\n",
    "        }\n",
    "    },\n",
    "    \"RF\": {\n",
    "        'model': RF(),\n",
    "        'params': {\n",
    "            'col__scaler__unit_variance': [True, False],\n",
    "            'col__vectorizer__lowercase': [True],\n",
    "            'col__vectorizer__strip_accents': ['ascii'],\n",
    "            'col__vectorizer__ngram_range': [(1,1), (1,2), (2,2)],\n",
    "            'col__vectorizer__max_df': np.geomspace(0.8, 1.0, 10),\n",
    "            'col__vectorizer__min_df': range(1, 5, 1),\n",
    "            'col__vectorizer__max_features': range(100, 1001, 100),\n",
    "            'col__vectorizer__binary': [True, False],\n",
    "            'col__vectorizer__norm': ['l1', 'l2'],\n",
    "            'col__vectorizer__use_idf': [True, False],\n",
    "            'col__vectorizer__smooth_idf': [True, False],\n",
    "            'col__vectorizer__sublinear_tf': [True, False],\n",
    "            'clf__criterion': ['gini', 'entropy'],\n",
    "            'clf__n_estimators': range(25, 201, 25),\n",
    "            'clf__max_depth': range(3, 9, 1),\n",
    "            'clf__max_features': ['sqrt', 'log2', None],\n",
    "            'clf__min_impurity_decrease': [0.00, 0.03, 0.06, 0.09, 0.12],\n",
    "            'clf__class_weight': ['balanced', 'balanced_subsample', None]\n",
    "        }\n",
    "    },\n",
    "    \"IF\":{\n",
    "        'model': IsolationForestClassifier(),\n",
    "        'params': {\n",
    "            'col__scaler__unit_variance': [True, False],\n",
    "            'col__vectorizer__lowercase': [True],\n",
    "            'col__vectorizer__strip_accents': ['ascii'],\n",
    "            'col__vectorizer__ngram_range': [(1,1), (1,2), (2,2)],\n",
    "            'col__vectorizer__max_df': np.geomspace(0.8, 1.0, 10),\n",
    "            'col__vectorizer__min_df': range(1, 5, 1),\n",
    "            'col__vectorizer__max_features': range(100, 1001, 100),\n",
    "            'col__vectorizer__binary': [True, False],\n",
    "            'col__vectorizer__norm': ['l1', 'l2'],\n",
    "            'col__vectorizer__use_idf': [True, False],\n",
    "            'col__vectorizer__smooth_idf': [True, False],\n",
    "            'col__vectorizer__sublinear_tf': [True, False],\n",
    "            'clf__n_estimators': range(25, 201, 25),\n",
    "            'clf__contamination': ['auto', *list(np.geomspace(0.01, 0.15, 10))]\n",
    "        }\n",
    "    },\n",
    "    \"DIC\": {\n",
    "        'model': DictionaryClassifier(),\n",
    "        'params': {\n",
    "            'col__vectorizer__lowercase': [True],\n",
    "            'col__vectorizer__strip_accents': ['ascii'],\n",
    "            'col__vectorizer__ngram_range': [(1,1)],\n",
    "            'col__vectorizer__binary': [True],\n",
    "            'col__vectorizer__use_idf': [False],\n",
    "            'col__vectorizer__smooth_idf': [False],\n",
    "            'col__vectorizer__vocabulary': [offensive_words]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83781a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DUMMY\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpedrocm/miniconda3/envs/tcc/lib/python3.8/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 3 is smaller than n_iter=100. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "GB\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "------------------------\n",
      "RF\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "------------------------\n",
      "IF\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "------------------------\n",
      "DIC\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpedrocm/miniconda3/envs/tcc/lib/python3.8/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "rcvs = {}\n",
    "\n",
    "for key in clfs.keys():\n",
    "    print(key)\n",
    "    \n",
    "    np.random.seed(32)\n",
    "    random.seed(24)\n",
    "    \n",
    "    chosen_clf = clfs[key]['model']\n",
    "    possible_params = clfs[key]['params']\n",
    "    \n",
    "    pipe_model = Pipeline(steps=[(\"col\", ColumnTransformer([(\"scaler\", \n",
    "                                                             RobustScaler(), \n",
    "                                                             list(range(1, 16))),\n",
    "                                                            \n",
    "                                                            (\"vectorizer\", \n",
    "                                                             TfidfVectorizer(stop_words=pt_stopwords),\n",
    "                                                             0)])),\n",
    "                                (\"clf\", chosen_clf)]\n",
    "                )\n",
    "        \n",
    "    rcv = RandomizedSearchCV(pipe_model, possible_params,\n",
    "                           scoring=METRICS,\n",
    "                           refit=FOCUS_METRIC,\n",
    "                           n_iter=COMBINATION_NB, cv=CV_NB, n_jobs=-1,\n",
    "                           return_train_score=True,\n",
    "                           verbose=1)\n",
    "\n",
    "    X = oos_dev_meta_lyrics.values\n",
    "    y = oos_dev_target.values\n",
    "    \n",
    "    rcv.fit(X=X, y=y)\n",
    "    \n",
    "    rcvs[key] = rcv\n",
    "    \n",
    "    print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ebe80354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:06<00:00,  1.29s/it]\n"
     ]
    }
   ],
   "source": [
    "oos_test_meta_lyrics = oos_test_set[['lyrics', *metadata_cols]]\n",
    "oos_test_target = oos_test_set[target]\n",
    "\n",
    "oos_meta_lyrics_metrics = pd.DataFrame(columns=[\"train_f1\", \"train_recall\", \"train_f1_macro\", \"train_recall_macro\",\n",
    "                                             \"test_f1\", \"test_recall\", \"test_f1_macro\", \"test_recall_macro\",\n",
    "                                             \"best_cv_score\", \"refit_time\", \"best_params\"])\n",
    "\n",
    "for key, best_rcv in tqdm(rcvs.items()):\n",
    "        \n",
    "    np.random.seed(32)\n",
    "    random.seed(24)\n",
    "    \n",
    "    y_dev_pred = best_rcv.predict(X=oos_dev_meta_lyrics.values)\n",
    "    train_f1_bin = f1_score(oos_dev_target.values, y_dev_pred)\n",
    "    train_recall_bin = recall_score(oos_dev_target.values, y_dev_pred)\n",
    "    train_f1_macro = f1_score(oos_dev_target.values, y_dev_pred, average='macro')\n",
    "    train_recall_macro = recall_score(oos_dev_target.values, y_dev_pred, average='macro')\n",
    "\n",
    "    y_test_pred = best_rcv.predict(X=oos_test_meta_lyrics.values)\n",
    "    test_f1_bin = f1_score(oos_test_target.values, y_test_pred)\n",
    "    test_recall_bin = recall_score(oos_test_target.values, y_test_pred)\n",
    "    test_f1_macro = f1_score(oos_test_target.values, y_test_pred, average='macro')\n",
    "    test_recall_macro = recall_score(oos_test_target.values, y_test_pred, average='macro')\n",
    "    \n",
    "    oos_meta_lyrics_metrics.loc[key] = [train_f1_bin, train_recall_bin, train_f1_macro, train_recall_macro,\n",
    "                                     test_f1_bin, test_recall_bin, test_f1_macro, test_recall_macro,\n",
    "                                     best_rcv.best_score_, best_rcv.refit_time_, str(best_rcv.best_params_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d3dfc840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1_macro</th>\n",
       "      <th>train_recall_macro</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>best_cv_score</th>\n",
       "      <th>refit_time</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DUMMY</th>\n",
       "      <td>0.057629</td>\n",
       "      <td>0.546584</td>\n",
       "      <td>0.360903</td>\n",
       "      <td>0.525106</td>\n",
       "      <td>0.085960</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.391508</td>\n",
       "      <td>0.523472</td>\n",
       "      <td>0.055143</td>\n",
       "      <td>0.648493</td>\n",
       "      <td>{'clf__strategy': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>0.845878</td>\n",
       "      <td>0.732919</td>\n",
       "      <td>0.921044</td>\n",
       "      <td>0.866460</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.578001</td>\n",
       "      <td>0.549255</td>\n",
       "      <td>0.198182</td>\n",
       "      <td>3.604882</td>\n",
       "      <td>{'col__vectorizer__use_idf': False, 'col__vect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.607059</td>\n",
       "      <td>0.801242</td>\n",
       "      <td>0.796073</td>\n",
       "      <td>0.888676</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.676183</td>\n",
       "      <td>0.739841</td>\n",
       "      <td>0.370286</td>\n",
       "      <td>2.060044</td>\n",
       "      <td>{'col__vectorizer__use_idf': False, 'col__vect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IF</th>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.155280</td>\n",
       "      <td>0.570703</td>\n",
       "      <td>0.567111</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.585207</td>\n",
       "      <td>0.572156</td>\n",
       "      <td>0.202495</td>\n",
       "      <td>1.832697</td>\n",
       "      <td>{'col__vectorizer__use_idf': True, 'col__vecto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIC</th>\n",
       "      <td>0.088181</td>\n",
       "      <td>0.894410</td>\n",
       "      <td>0.365938</td>\n",
       "      <td>0.685216</td>\n",
       "      <td>0.112224</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.310819</td>\n",
       "      <td>0.638053</td>\n",
       "      <td>0.129390</td>\n",
       "      <td>0.719949</td>\n",
       "      <td>{'col__vectorizer__vocabulary': {'anus': 0, '-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_f1  train_recall  train_f1_macro  train_recall_macro   test_f1  \\\n",
       "DUMMY  0.057629      0.546584        0.360903            0.525106  0.085960   \n",
       "GB     0.845878      0.732919        0.921044            0.866460  0.176471   \n",
       "RF     0.607059      0.801242        0.796073            0.888676  0.390244   \n",
       "IF     0.163934      0.155280        0.570703            0.567111  0.200000   \n",
       "DIC    0.088181      0.894410        0.365938            0.685216  0.112224   \n",
       "\n",
       "       test_recall  test_f1_macro  test_recall_macro  best_cv_score  \\\n",
       "DUMMY     0.500000       0.391508           0.523472       0.055143   \n",
       "GB        0.100000       0.578001           0.549255       0.198182   \n",
       "RF        0.533333       0.676183           0.739841       0.370286   \n",
       "IF        0.166667       0.585207           0.572156       0.202495   \n",
       "DIC       0.933333       0.310819           0.638053       0.129390   \n",
       "\n",
       "       refit_time                                        best_params  \n",
       "DUMMY    0.648493                       {'clf__strategy': 'uniform'}  \n",
       "GB       3.604882  {'col__vectorizer__use_idf': False, 'col__vect...  \n",
       "RF       2.060044  {'col__vectorizer__use_idf': False, 'col__vect...  \n",
       "IF       1.832697  {'col__vectorizer__use_idf': True, 'col__vecto...  \n",
       "DIC      0.719949  {'col__vectorizer__vocabulary': {'anus': 0, '-...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oos_meta_lyrics_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "764fd805",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_meta_lyrics_metrics.to_csv('results/oos_meta_lyrics_metrics.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483c17a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
