{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c23fa671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54e6a756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GB\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.ensemble import IsolationForest as IF\n",
    "from sklearn.dummy import DummyClassifier as DC\n",
    "from sklearn.base import ClassifierMixin, BaseEstimator\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d20b9c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bf3451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy, copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b6bc00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81653e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fc67dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fe587a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_dev_set = pd.read_csv(\"data/dataset/oos_dev_set.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a43b47c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_test_set = pd.read_csv(\"data/dataset/oos_test_set.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eebefa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"explicit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "401e77d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lyrics', 'artist', 'song', 'album_name', 'popularity', 'danceability',\n",
       "       'energy', 'key', 'mode', 'valence', 'tempo', 'duration_ms',\n",
       "       'acousticness', 'liveness', 'loudness', 'speechiness', 'time_signature',\n",
       "       'explicit', 'nb_genres', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oos_dev_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eda74beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_cols = ['popularity', 'danceability','energy', 'key', 'mode', 'valence', 'tempo', 'duration_ms',\n",
    "'acousticness', 'liveness', 'loudness', 'speechiness', 'time_signature', 'nb_genres', 'year']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1532e8",
   "metadata": {},
   "source": [
    "# Custom Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "639ade88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IsolationForestClassifier(ClassifierMixin, BaseEstimator):\n",
    "    \n",
    "    def __init__(self, **params):\n",
    "        self.estimator = IF(**params)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        \n",
    "        self.estimator.fit(X)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \n",
    "        preds = self.estimator.predict(X)\n",
    "\n",
    "        return np.array(list(map(lambda p: 0 if p==1 else 1, preds)))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.transform(X)\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return self.estimator.get_params()\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        self.estimator.set_params(**parameters)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ab6edc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_NB = 5\n",
    "COMBINATION_NB = 50\n",
    "METRICS = [\"f1\", \"recall\", \"f1_macro\", \"recall_macro\"]\n",
    "FOCUS_METRIC = \"recall\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52acf52",
   "metadata": {},
   "source": [
    "# Metadata Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1029c172",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_dev_metadata = oos_dev_set[metadata_cols]\n",
    "oos_dev_target = oos_dev_set[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddb540f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    \"DUMMY\": {\n",
    "        'model': DC(),\n",
    "        'params': {\n",
    "            'clf__strategy': ['most_frequent', 'uniform', 'stratified']\n",
    "        }\n",
    "    },\n",
    "    \"GB\": {\n",
    "        'model': GB(),\n",
    "        'params': {\n",
    "            'scaler__unit_variance': [True, False],\n",
    "            'clf__loss': ['deviance', 'exponential'],\n",
    "            'clf__n_estimators': range(25, 201, 25),\n",
    "            'clf__learning_rate': np.geomspace(0.01, 0.2, 10),\n",
    "            'clf__max_depth': [3, 4, 5],\n",
    "            'clf__max_features': ['sqrt', 'log2', None],\n",
    "            'clf__min_impurity_decrease': [0.00, 0.03, 0.06, 0.09, 0.12]\n",
    "        }\n",
    "    },\n",
    "    \"RF\": {\n",
    "        'model': RF(),\n",
    "        'params': {\n",
    "            'scaler__unit_variance': [True, False],\n",
    "            'clf__criterion': ['gini', 'entropy'],\n",
    "            'clf__n_estimators': range(25, 201, 25),\n",
    "            'clf__max_depth': range(3, 9, 1),\n",
    "            'clf__max_features': ['sqrt', 'log2', None],\n",
    "            'clf__min_impurity_decrease': [0.00, 0.03, 0.06, 0.09, 0.12],\n",
    "            'clf__class_weight': ['balanced', 'balanced_subsample', None]\n",
    "        }\n",
    "    },\n",
    "    \"IF\":{\n",
    "        'model': IsolationForestClassifier(),\n",
    "        'params': {\n",
    "            'scaler__unit_variance': [True, False],\n",
    "            'clf__n_estimators': range(25, 201, 25),\n",
    "            'clf__contamination': ['auto', *list(np.geomspace(0.01, 0.15, 10))]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb958762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DUMMY\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpedrocm/miniconda3/envs/tcc/lib/python3.8/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 3 is smaller than n_iter=50. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "GB\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "------------------------\n",
      "RF\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "------------------------\n",
      "IF\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "rcvs = {}\n",
    "\n",
    "for key in clfs.keys():\n",
    "    print(key)\n",
    "    \n",
    "    np.random.seed(32)\n",
    "    random.seed(24)\n",
    "    \n",
    "    chosen_clf = clfs[key]['model']\n",
    "    possible_params = clfs[key]['params']\n",
    "    \n",
    "    pipe_model = Pipeline(steps=[(\"scaler\", RobustScaler()),\n",
    "                                (\"clf\", chosen_clf)]\n",
    "                )\n",
    "        \n",
    "    rcv = RandomizedSearchCV(pipe_model, possible_params,\n",
    "                           scoring=METRICS,\n",
    "                           refit=FOCUS_METRIC,\n",
    "                           n_iter=COMBINATION_NB, cv=CV_NB, n_jobs=-1,\n",
    "                           return_train_score=True,\n",
    "                           verbose=1)\n",
    "\n",
    "    X = oos_dev_metadata.values\n",
    "    y = oos_dev_target.values\n",
    "    \n",
    "    rcv.fit(X=X, y=y)\n",
    "    \n",
    "    rcvs[key] = rcv\n",
    "    \n",
    "    print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69ceeaa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 17.92it/s]\n"
     ]
    }
   ],
   "source": [
    "oos_test_metadata = oos_test_set[metadata_cols]\n",
    "oos_test_target = oos_test_set[target]\n",
    "\n",
    "oos_metadata_metrics = pd.DataFrame(columns=[\"train_f1\", \"train_recall\", \"train_f1_macro\", \"train_recall_macro\",\n",
    "                                             \"test_f1\", \"test_recall\", \"test_f1_macro\", \"test_recall_macro\",\n",
    "                                             \"best_cv_score\", \"refit_time\", \"best_params\"])\n",
    "\n",
    "for key, best_rcv in tqdm(rcvs.items()):\n",
    "        \n",
    "    np.random.seed(32)\n",
    "    random.seed(24)\n",
    "    \n",
    "    y_dev_pred = best_rcv.predict(X=oos_dev_metadata.values)\n",
    "    train_f1_bin = f1_score(oos_dev_target.values, y_dev_pred)\n",
    "    train_recall_bin = recall_score(oos_dev_target.values, y_dev_pred)\n",
    "    train_f1_macro = f1_score(oos_dev_target.values, y_dev_pred, average='macro')\n",
    "    train_recall_macro = recall_score(oos_dev_target.values, y_dev_pred, average='macro')\n",
    "\n",
    "    y_test_pred = best_rcv.predict(X=oos_test_metadata.values)\n",
    "    test_f1_bin = f1_score(oos_test_target.values, y_test_pred)\n",
    "    test_recall_bin = recall_score(oos_test_target.values, y_test_pred)\n",
    "    test_f1_macro = f1_score(oos_test_target.values, y_test_pred, average='macro')\n",
    "    test_recall_macro = recall_score(oos_test_target.values, y_test_pred, average='macro')\n",
    "    \n",
    "    oos_metadata_metrics.loc[key] = [train_f1_bin, train_recall_bin, train_f1_macro, train_recall_macro,\n",
    "                                     test_f1_bin, test_recall_bin, test_f1_macro, test_recall_macro,\n",
    "                                     best_rcv.best_score_, best_rcv.refit_time_, str(best_rcv.best_params_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6c890c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1_macro</th>\n",
       "      <th>train_recall_macro</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>best_cv_score</th>\n",
       "      <th>refit_time</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DUMMY</th>\n",
       "      <td>0.057629</td>\n",
       "      <td>0.546584</td>\n",
       "      <td>0.360903</td>\n",
       "      <td>0.525106</td>\n",
       "      <td>0.085960</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.391508</td>\n",
       "      <td>0.523472</td>\n",
       "      <td>0.484280</td>\n",
       "      <td>0.008734</td>\n",
       "      <td>{'clf__strategy': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>0.536170</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.763300</td>\n",
       "      <td>0.694679</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.628129</td>\n",
       "      <td>0.594784</td>\n",
       "      <td>0.267803</td>\n",
       "      <td>0.247795</td>\n",
       "      <td>{'scaler__unit_variance': True, 'clf__n_estima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.265625</td>\n",
       "      <td>0.844720</td>\n",
       "      <td>0.597341</td>\n",
       "      <td>0.858035</td>\n",
       "      <td>0.301676</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.599734</td>\n",
       "      <td>0.859091</td>\n",
       "      <td>0.763068</td>\n",
       "      <td>0.385020</td>\n",
       "      <td>{'scaler__unit_variance': True, 'clf__n_estima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IF</th>\n",
       "      <td>0.104132</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.500021</td>\n",
       "      <td>0.608411</td>\n",
       "      <td>0.167832</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.536656</td>\n",
       "      <td>0.624739</td>\n",
       "      <td>0.409470</td>\n",
       "      <td>0.077377</td>\n",
       "      <td>{'scaler__unit_variance': True, 'clf__n_estima...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_f1  train_recall  train_f1_macro  train_recall_macro   test_f1  \\\n",
       "DUMMY  0.057629      0.546584        0.360903            0.525106  0.085960   \n",
       "GB     0.536170      0.391304        0.763300            0.694679  0.279070   \n",
       "RF     0.265625      0.844720        0.597341            0.858035  0.301676   \n",
       "IF     0.104132      0.391304        0.500021            0.608411  0.167832   \n",
       "\n",
       "       test_recall  test_f1_macro  test_recall_macro  best_cv_score  \\\n",
       "DUMMY          0.5       0.391508           0.523472       0.484280   \n",
       "GB             0.2       0.628129           0.594784       0.267803   \n",
       "RF             0.9       0.599734           0.859091       0.763068   \n",
       "IF             0.4       0.536656           0.624739       0.409470   \n",
       "\n",
       "       refit_time                                        best_params  \n",
       "DUMMY    0.008734                       {'clf__strategy': 'uniform'}  \n",
       "GB       0.247795  {'scaler__unit_variance': True, 'clf__n_estima...  \n",
       "RF       0.385020  {'scaler__unit_variance': True, 'clf__n_estima...  \n",
       "IF       0.077377  {'scaler__unit_variance': True, 'clf__n_estima...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oos_metadata_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff6a602d",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_metadata_metrics.to_csv('results/metadata_metrics.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a922663",
   "metadata": {},
   "source": [
    "# Lyrics Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67dfbcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_dev_lyrics = oos_dev_set[['lyrics']]\n",
    "oos_dev_target = oos_dev_set[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b012571f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    \"DUMMY\": {\n",
    "        'model': DC(),\n",
    "        'params': {\n",
    "            'clf__strategy': ['most_frequent', 'uniform', 'stratified']\n",
    "        }\n",
    "    },\n",
    "    \"GB\": {\n",
    "        'model': GB(),\n",
    "        'params': {\n",
    "            'txt__vectorizer__lowercase': [True, False],\n",
    "            'txt__vectorizer__strip_accents': ['ascii', None],\n",
    "            'txt__vectorizer__ngram_range': [(1,1), (1,2), (2,2)],\n",
    "            'txt__vectorizer__max_df': np.geomspace(0.8, 1.0, 10),\n",
    "            'txt__vectorizer__min_df': range(1, 5, 1),\n",
    "            'txt__vectorizer__max_features': range(100, 1001, 100),\n",
    "            'txt__vectorizer__binary': [True, False],\n",
    "            'txt__vectorizer__norm': ['l1', 'l2'],\n",
    "            'txt__vectorizer__use_idf': [True, False],\n",
    "            'txt__vectorizer__smooth_idf': [True, False],\n",
    "            'txt__vectorizer__sublinear_tf': [True, False],\n",
    "            'clf__loss': ['deviance', 'exponential'],\n",
    "            'clf__n_estimators': range(25, 201, 25),\n",
    "            'clf__learning_rate': np.geomspace(0.01, 0.2, 10),\n",
    "            'clf__max_depth': [3, 4, 5],\n",
    "            'clf__max_features': ['sqrt', 'log2', None],\n",
    "            'clf__min_impurity_decrease': [0.00, 0.03, 0.06, 0.09, 0.12]\n",
    "        }\n",
    "    },\n",
    "    \"RF\": {\n",
    "        'model': RF(),\n",
    "        'params': {\n",
    "            'txt__vectorizer__lowercase': [True, False],\n",
    "            'txt__vectorizer__strip_accents': ['ascii', None],\n",
    "            'txt__vectorizer__ngram_range': [(1,1), (1,2), (2,2)],\n",
    "            'txt__vectorizer__max_df': np.geomspace(0.8, 1.0, 10),\n",
    "            'txt__vectorizer__min_df': range(1, 5, 1),\n",
    "            'txt__vectorizer__max_features': range(100, 1001, 100),\n",
    "            'txt__vectorizer__binary': [True, False],\n",
    "            'txt__vectorizer__norm': ['l1', 'l2'],\n",
    "            'txt__vectorizer__use_idf': [True, False],\n",
    "            'txt__vectorizer__smooth_idf': [True, False],\n",
    "            'txt__vectorizer__sublinear_tf': [True, False],\n",
    "            'clf__criterion': ['gini', 'entropy'],\n",
    "            'clf__n_estimators': range(25, 201, 25),\n",
    "            'clf__max_depth': range(3, 9, 1),\n",
    "            'clf__max_features': ['sqrt', 'log2', None],\n",
    "            'clf__min_impurity_decrease': [0.00, 0.03, 0.06, 0.09, 0.12],\n",
    "            'clf__class_weight': ['balanced', 'balanced_subsample', None]\n",
    "        }\n",
    "    },\n",
    "    \"IF\":{\n",
    "        'model': IsolationForestClassifier(),\n",
    "        'params': {\n",
    "            'txt__vectorizer__lowercase': [True, False],\n",
    "            'txt__vectorizer__strip_accents': ['ascii', None],\n",
    "            'txt__vectorizer__ngram_range': [(1,1), (1,2), (2,2)],\n",
    "            'txt__vectorizer__max_df': np.geomspace(0.8, 1.0, 10),\n",
    "            'txt__vectorizer__min_df': range(1, 5, 1),\n",
    "            'txt__vectorizer__max_features': range(100, 1001, 100),\n",
    "            'txt__vectorizer__binary': [True, False],\n",
    "            'txt__vectorizer__norm': ['l1', 'l2'],\n",
    "            'txt__vectorizer__use_idf': [True, False],\n",
    "            'txt__vectorizer__smooth_idf': [True, False],\n",
    "            'txt__vectorizer__sublinear_tf': [True, False],\n",
    "            'clf__n_estimators': range(25, 201, 25),\n",
    "            'clf__contamination': ['auto', *list(np.geomspace(0.01, 0.15, 10))]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6ead887f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DUMMY\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "------------------------\n",
      "GB\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "------------------------\n",
      "RF\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "------------------------\n",
      "IF\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "rcvs = {}\n",
    "\n",
    "for key in clfs.keys():\n",
    "    print(key)\n",
    "    \n",
    "    np.random.seed(32)\n",
    "    random.seed(24)\n",
    "    \n",
    "    chosen_clf = clfs[key]['model']\n",
    "    possible_params = clfs[key]['params']\n",
    "    \n",
    "    pipe_model = Pipeline(steps=[(\"txt\", ColumnTransformer([(\"vectorizer\", \n",
    "                                                             TfidfVectorizer(), \n",
    "                                                             0)])),\n",
    "                                (\"clf\", chosen_clf)]\n",
    "                )\n",
    "        \n",
    "    rcv = RandomizedSearchCV(pipe_model, possible_params,\n",
    "                           scoring=METRICS,\n",
    "                           refit=FOCUS_METRIC,\n",
    "                           n_iter=COMBINATION_NB, cv=CV_NB, n_jobs=-1,\n",
    "                           return_train_score=True,\n",
    "                           verbose=1)\n",
    "\n",
    "    X = oos_dev_lyrics.values\n",
    "    y = oos_dev_target.values\n",
    "    \n",
    "    rcv.fit(X=X, y=y)\n",
    "    \n",
    "    rcvs[key] = rcv\n",
    "    \n",
    "    print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3c7d8773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.22s/it]\n"
     ]
    }
   ],
   "source": [
    "oos_test_lyrics = oos_test_set[['lyrics']]\n",
    "oos_test_target = oos_test_set[target]\n",
    "\n",
    "oos_lyrics_metrics = pd.DataFrame(columns=[\"train_f1\", \"train_recall\", \"train_f1_macro\", \"train_recall_macro\",\n",
    "                                             \"test_f1\", \"test_recall\", \"test_f1_macro\", \"test_recall_macro\",\n",
    "                                             \"best_cv_score\", \"refit_time\", \"best_params\"])\n",
    "\n",
    "for key, best_rcv in tqdm(rcvs.items()):\n",
    "        \n",
    "    np.random.seed(32)\n",
    "    random.seed(24)\n",
    "    \n",
    "    y_dev_pred = best_rcv.predict(X=oos_dev_lyrics.values)\n",
    "    train_f1_bin = f1_score(oos_dev_target.values, y_dev_pred)\n",
    "    train_recall_bin = recall_score(oos_dev_target.values, y_dev_pred)\n",
    "    train_f1_macro = f1_score(oos_dev_target.values, y_dev_pred, average='macro')\n",
    "    train_recall_macro = recall_score(oos_dev_target.values, y_dev_pred, average='macro')\n",
    "\n",
    "    y_test_pred = best_rcv.predict(X=oos_test_lyrics.values)\n",
    "    test_f1_bin = f1_score(oos_test_target.values, y_test_pred)\n",
    "    test_recall_bin = recall_score(oos_test_target.values, y_test_pred)\n",
    "    test_f1_macro = f1_score(oos_test_target.values, y_test_pred, average='macro')\n",
    "    test_recall_macro = recall_score(oos_test_target.values, y_test_pred, average='macro')\n",
    "    \n",
    "    oos_lyrics_metrics.loc[key] = [train_f1_bin, train_recall_bin, train_f1_macro, train_recall_macro,\n",
    "                                     test_f1_bin, test_recall_bin, test_f1_macro, test_recall_macro,\n",
    "                                     best_rcv.best_score_, best_rcv.refit_time_, str(best_rcv.best_params_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c004f281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1_macro</th>\n",
       "      <th>train_recall_macro</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>best_cv_score</th>\n",
       "      <th>refit_time</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DUMMY</th>\n",
       "      <td>0.057629</td>\n",
       "      <td>0.546584</td>\n",
       "      <td>0.360903</td>\n",
       "      <td>0.525106</td>\n",
       "      <td>0.085960</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.391508</td>\n",
       "      <td>0.523472</td>\n",
       "      <td>0.051872</td>\n",
       "      <td>0.695503</td>\n",
       "      <td>{'clf__strategy': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>0.542986</td>\n",
       "      <td>0.372671</td>\n",
       "      <td>0.767065</td>\n",
       "      <td>0.686335</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.517716</td>\n",
       "      <td>0.514431</td>\n",
       "      <td>0.143824</td>\n",
       "      <td>8.608728</td>\n",
       "      <td>{'txt__vectorizer__use_idf': False, 'txt__vect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.368231</td>\n",
       "      <td>0.633540</td>\n",
       "      <td>0.668307</td>\n",
       "      <td>0.791023</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.648385</td>\n",
       "      <td>0.717958</td>\n",
       "      <td>0.365641</td>\n",
       "      <td>0.997802</td>\n",
       "      <td>{'clf__n_estimators': 175, 'clf__min_impurity_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IF</th>\n",
       "      <td>0.135211</td>\n",
       "      <td>0.149068</td>\n",
       "      <td>0.553984</td>\n",
       "      <td>0.559493</td>\n",
       "      <td>0.109091</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.536357</td>\n",
       "      <td>0.533607</td>\n",
       "      <td>0.176754</td>\n",
       "      <td>2.634795</td>\n",
       "      <td>{'clf__n_estimators': 150, 'clf__contamination...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_f1  train_recall  train_f1_macro  train_recall_macro   test_f1  \\\n",
       "DUMMY  0.057629      0.546584        0.360903            0.525106  0.085960   \n",
       "GB     0.542986      0.372671        0.767065            0.686335  0.058824   \n",
       "RF     0.368231      0.633540        0.668307            0.791023  0.340909   \n",
       "IF     0.135211      0.149068        0.553984            0.559493  0.109091   \n",
       "\n",
       "       test_recall  test_f1_macro  test_recall_macro  best_cv_score  \\\n",
       "DUMMY     0.500000       0.391508           0.523472       0.051872   \n",
       "GB        0.033333       0.517716           0.514431       0.143824   \n",
       "RF        0.500000       0.648385           0.717958       0.365641   \n",
       "IF        0.100000       0.536357           0.533607       0.176754   \n",
       "\n",
       "       refit_time                                        best_params  \n",
       "DUMMY    0.695503                       {'clf__strategy': 'uniform'}  \n",
       "GB       8.608728  {'txt__vectorizer__use_idf': False, 'txt__vect...  \n",
       "RF       0.997802  {'clf__n_estimators': 175, 'clf__min_impurity_...  \n",
       "IF       2.634795  {'clf__n_estimators': 150, 'clf__contamination...  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oos_lyrics_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edddefcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_lyrics_metrics.to_csv('results/lyrics_metrics.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c21b71",
   "metadata": {},
   "source": [
    "# Lyrics and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a272dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_dev_meta_lyrics = oos_dev_set[['lyrics', *metadata_cols]]\n",
    "oos_dev_target = oos_dev_set[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24796cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    \"DUMMY\": {\n",
    "        'model': DC(),\n",
    "        'params': {\n",
    "            'clf__strategy': ['most_frequent', 'uniform', 'stratified']\n",
    "        }\n",
    "    },\n",
    "    \"GB\": {\n",
    "        'model': GB(),\n",
    "        'params': {\n",
    "            'col__scaler__unit_variance': [True, False],\n",
    "            'col__vectorizer__lowercase': [True, False],\n",
    "            'col__vectorizer__strip_accents': ['ascii', None],\n",
    "            'col__vectorizer__ngram_range': [(1,1), (1,2), (2,2)],\n",
    "            'col__vectorizer__max_df': np.geomspace(0.8, 1.0, 10),\n",
    "            'col__vectorizer__min_df': range(1, 5, 1),\n",
    "            'col__vectorizer__max_features': range(100, 1001, 100),\n",
    "            'col__vectorizer__binary': [True, False],\n",
    "            'col__vectorizer__norm': ['l1', 'l2'],\n",
    "            'col__vectorizer__use_idf': [True, False],\n",
    "            'col__vectorizer__smooth_idf': [True, False],\n",
    "            'col__vectorizer__sublinear_tf': [True, False],\n",
    "            'clf__loss': ['deviance', 'exponential'],\n",
    "            'clf__n_estimators': range(25, 201, 25),\n",
    "            'clf__learning_rate': np.geomspace(0.01, 0.2, 10),\n",
    "            'clf__max_depth': [3, 4, 5],\n",
    "            'clf__max_features': ['sqrt', 'log2', None],\n",
    "            'clf__min_impurity_decrease': [0.00, 0.03, 0.06, 0.09, 0.12]\n",
    "        }\n",
    "    },\n",
    "    \"RF\": {\n",
    "        'model': RF(),\n",
    "        'params': {\n",
    "            'col__scaler__unit_variance': [True, False],\n",
    "            'col__vectorizer__lowercase': [True, False],\n",
    "            'col__vectorizer__strip_accents': ['ascii', None],\n",
    "            'col__vectorizer__ngram_range': [(1,1), (1,2), (2,2)],\n",
    "            'col__vectorizer__max_df': np.geomspace(0.8, 1.0, 10),\n",
    "            'col__vectorizer__min_df': range(1, 5, 1),\n",
    "            'col__vectorizer__max_features': range(100, 1001, 100),\n",
    "            'col__vectorizer__binary': [True, False],\n",
    "            'col__vectorizer__norm': ['l1', 'l2'],\n",
    "            'col__vectorizer__use_idf': [True, False],\n",
    "            'col__vectorizer__smooth_idf': [True, False],\n",
    "            'col__vectorizer__sublinear_tf': [True, False],\n",
    "            'clf__criterion': ['gini', 'entropy'],\n",
    "            'clf__n_estimators': range(25, 201, 25),\n",
    "            'clf__max_depth': range(3, 9, 1),\n",
    "            'clf__max_features': ['sqrt', 'log2', None],\n",
    "            'clf__min_impurity_decrease': [0.00, 0.03, 0.06, 0.09, 0.12],\n",
    "            'clf__class_weight': ['balanced', 'balanced_subsample', None]\n",
    "        }\n",
    "    },\n",
    "    \"IF\":{\n",
    "        'model': IsolationForestClassifier(),\n",
    "        'params': {\n",
    "            'col__scaler__unit_variance': [True, False],\n",
    "            'col__vectorizer__lowercase': [True, False],\n",
    "            'col__vectorizer__strip_accents': ['ascii', None],\n",
    "            'col__vectorizer__ngram_range': [(1,1), (1,2), (2,2)],\n",
    "            'col__vectorizer__max_df': np.geomspace(0.8, 1.0, 10),\n",
    "            'col__vectorizer__min_df': range(1, 5, 1),\n",
    "            'col__vectorizer__max_features': range(100, 1001, 100),\n",
    "            'col__vectorizer__binary': [True, False],\n",
    "            'col__vectorizer__norm': ['l1', 'l2'],\n",
    "            'col__vectorizer__use_idf': [True, False],\n",
    "            'col__vectorizer__smooth_idf': [True, False],\n",
    "            'col__vectorizer__sublinear_tf': [True, False],\n",
    "            'clf__n_estimators': range(25, 201, 25),\n",
    "            'clf__contamination': ['auto', *list(np.geomspace(0.01, 0.15, 10))]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83781a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DUMMY\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpedrocm/miniconda3/envs/tcc/lib/python3.8/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 3 is smaller than n_iter=10. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "GB\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "------------------------\n",
      "RF\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "------------------------\n",
      "IF\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "rcvs = {}\n",
    "\n",
    "for key in clfs.keys():\n",
    "    print(key)\n",
    "    \n",
    "    np.random.seed(32)\n",
    "    random.seed(24)\n",
    "    \n",
    "    chosen_clf = clfs[key]['model']\n",
    "    possible_params = clfs[key]['params']\n",
    "    \n",
    "    pipe_model = Pipeline(steps=[(\"col\", ColumnTransformer([(\"scaler\", RobustScaler(), list(range(1, 16))),\n",
    "                                                            (\"vectorizer\", TfidfVectorizer(), 0)])),\n",
    "                                (\"clf\", chosen_clf)]\n",
    "                )\n",
    "        \n",
    "    rcv = RandomizedSearchCV(pipe_model, possible_params,\n",
    "                           scoring=METRICS,\n",
    "                           refit=FOCUS_METRIC,\n",
    "                           n_iter=COMBINATION_NB, cv=CV_NB, n_jobs=-1,\n",
    "                           return_train_score=True,\n",
    "                           verbose=1)\n",
    "\n",
    "    X = oos_dev_meta_lyrics.values\n",
    "    y = oos_dev_target.values\n",
    "    \n",
    "    rcv.fit(X=X, y=y)\n",
    "    \n",
    "    rcvs[key] = rcv\n",
    "    \n",
    "    print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebe80354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.30s/it]\n"
     ]
    }
   ],
   "source": [
    "oos_test_meta_lyrics = oos_test_set[['lyrics', *metadata_cols]]\n",
    "oos_test_target = oos_test_set[target]\n",
    "\n",
    "oos_meta_lyrics_metrics = pd.DataFrame(columns=[\"train_f1\", \"train_recall\", \"train_f1_macro\", \"train_recall_macro\",\n",
    "                                             \"test_f1\", \"test_recall\", \"test_f1_macro\", \"test_recall_macro\",\n",
    "                                             \"best_cv_score\", \"refit_time\", \"best_params\"])\n",
    "\n",
    "for key, best_rcv in tqdm(rcvs.items()):\n",
    "        \n",
    "    np.random.seed(32)\n",
    "    random.seed(24)\n",
    "    \n",
    "    y_dev_pred = best_rcv.predict(X=oos_dev_meta_lyrics.values)\n",
    "    train_f1_bin = f1_score(oos_dev_target.values, y_dev_pred)\n",
    "    train_recall_bin = recall_score(oos_dev_target.values, y_dev_pred)\n",
    "    train_f1_macro = f1_score(oos_dev_target.values, y_dev_pred, average='macro')\n",
    "    train_recall_macro = recall_score(oos_dev_target.values, y_dev_pred, average='macro')\n",
    "\n",
    "    y_test_pred = best_rcv.predict(X=oos_test_meta_lyrics.values)\n",
    "    test_f1_bin = f1_score(oos_test_target.values, y_test_pred)\n",
    "    test_recall_bin = recall_score(oos_test_target.values, y_test_pred)\n",
    "    test_f1_macro = f1_score(oos_test_target.values, y_test_pred, average='macro')\n",
    "    test_recall_macro = recall_score(oos_test_target.values, y_test_pred, average='macro')\n",
    "    \n",
    "    oos_meta_lyrics_metrics.loc[key] = [train_f1_bin, train_recall_bin, train_f1_macro, train_recall_macro,\n",
    "                                     test_f1_bin, test_recall_bin, test_f1_macro, test_recall_macro,\n",
    "                                     best_rcv.best_score_, best_rcv.refit_time_, str(best_rcv.best_params_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3dfc840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1_macro</th>\n",
       "      <th>train_recall_macro</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>best_cv_score</th>\n",
       "      <th>refit_time</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DUMMY</th>\n",
       "      <td>0.057629</td>\n",
       "      <td>0.546584</td>\n",
       "      <td>0.360903</td>\n",
       "      <td>0.525106</td>\n",
       "      <td>0.085960</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.391508</td>\n",
       "      <td>0.523472</td>\n",
       "      <td>0.050678</td>\n",
       "      <td>0.786750</td>\n",
       "      <td>{'clf__strategy': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.594266</td>\n",
       "      <td>0.563686</td>\n",
       "      <td>0.119171</td>\n",
       "      <td>3.725462</td>\n",
       "      <td>{'col__vectorizer__use_idf': True, 'col__vecto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.264039</td>\n",
       "      <td>0.832298</td>\n",
       "      <td>0.596814</td>\n",
       "      <td>0.852444</td>\n",
       "      <td>0.315152</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.611901</td>\n",
       "      <td>0.852111</td>\n",
       "      <td>0.228460</td>\n",
       "      <td>2.804922</td>\n",
       "      <td>{'col__vectorizer__use_idf': False, 'col__vect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IF</th>\n",
       "      <td>0.156716</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.568408</td>\n",
       "      <td>0.557608</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.601118</td>\n",
       "      <td>0.576627</td>\n",
       "      <td>0.180356</td>\n",
       "      <td>1.875922</td>\n",
       "      <td>{'col__vectorizer__use_idf': True, 'col__vecto...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_f1  train_recall  train_f1_macro  train_recall_macro   test_f1  \\\n",
       "DUMMY  0.057629      0.546584        0.360903            0.525106  0.085960   \n",
       "GB     1.000000      1.000000        1.000000            1.000000  0.210526   \n",
       "RF     0.264039      0.832298        0.596814            0.852444  0.315152   \n",
       "IF     0.156716      0.130435        0.568408            0.557608  0.227273   \n",
       "\n",
       "       test_recall  test_f1_macro  test_recall_macro  best_cv_score  \\\n",
       "DUMMY     0.500000       0.391508           0.523472       0.050678   \n",
       "GB        0.133333       0.594266           0.563686       0.119171   \n",
       "RF        0.866667       0.611901           0.852111       0.228460   \n",
       "IF        0.166667       0.601118           0.576627       0.180356   \n",
       "\n",
       "       refit_time                                        best_params  \n",
       "DUMMY    0.786750                       {'clf__strategy': 'uniform'}  \n",
       "GB       3.725462  {'col__vectorizer__use_idf': True, 'col__vecto...  \n",
       "RF       2.804922  {'col__vectorizer__use_idf': False, 'col__vect...  \n",
       "IF       1.875922  {'col__vectorizer__use_idf': True, 'col__vecto...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oos_meta_lyrics_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764fd805",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_meta_lyrics_metrics.to_csv('results/meta_lyrics_metrics.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
